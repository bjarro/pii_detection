{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e54e6d4-1fed-4d5d-b4fb-1d6c41ffbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thorn\\AppData\\Local\\Temp\\ipykernel_9220\\819515313.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was too old on your system - pyarrow 10.0.1 is the current minimum supported version as of this release.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2dc9a7-6cee-43df-b0b5-8642364b121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d913122-ec1d-4b72-b475-7ddf736ef6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFDebertaForTokenClassification, DebertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d092ea-0b12-4acd-aa80-c97ae6d54b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885aebb-8f7c-4bcf-ab49-e3f8c8cc552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec400b-71a2-49e2-a8fe-1fbc8a630711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a141d91-c666-4d08-8dab-329a32911e7b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ecb9e-7fa2-4cec-9ee8-a4c8db805816",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = './in/train.json'\n",
    "path_test = './in/test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367dcb67-6d0f-48c1-bcea-321529ceb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = json.load(open(path_train))\n",
    "df_train = pd.json_normalize(train_json)\n",
    "\n",
    "test_json = json.load(open(path_test))\n",
    "df_test = pd.json_normalize(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982c426d-74dd-416b-acf0-c27c11b74a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e7f7e-8e07-4381-9b17-8123fd8d1165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071f037-6282-42e9-bd14-b52d263b389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = \"\"\"Meet Jane Doe, a brilliant student at XYZ University. She can be reached at jane.doe@email.com or through her phone number +1234567890. Jane resides at 123 Main Street, Cityville. Her student ID is 987654 and her personal website is www.janedoe.com. Connect with her on social media using the username @janedoe.\n",
    "\n",
    "Meanwhile, John Smith, another outstanding student, can be contacted at john.smith@email.com or at +9876543210. John lives at 456 Oak Avenue, Townsville. His student ID is 123456, and you can visit his personal blog at www.johnsmithblog.com. Follow him on Twitter with the handle @johnsmith123.\n",
    "\n",
    "For any inquiries about the university's programs, you can contact the administration office at admin@xyzuniversity.edu or call +5551234567. The office is located at 789 University Boulevard.\n",
    "\n",
    "Visit our official website at www.xyzuniversity.edu for more information on courses and admission procedures.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e1991-c150-4cc2-a893-f022fbe63f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72253e2b-298b-462f-b3ec-b8b2c53feedf",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea28e58-75cd-45e4-89ad-eed3a6228c3f",
   "metadata": {},
   "source": [
    "## Run (lakshyakh93/deberta_finetuned_pii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40674e-3f1c-45f6-9521-0abe9e43077e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_text = df_train.loc[0].full_text\n",
    "text = full_text\n",
    "model_name = \"lakshyakh93/deberta_finetuned_pii\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer(text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_token_class_ids = logits.argmax(-1)\n",
    "\n",
    "# Note that tokens are classified rather then input words which means that\n",
    "# there might be more predicted token classes than words.\n",
    "# Multiple token classes might account for the same word\n",
    "predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]\n",
    "\n",
    "labels = predicted_token_class_ids\n",
    "loss = model(**inputs, labels=labels).loss\n",
    "\n",
    "predicted_tokens_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9baac6d-56aa-41f9-85c3-54f6c382386e",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81fa47-68ba-4ae6-9be8-6e0e81a8ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "gen = pipeline(\"token-classification\", \"lakshyakh93/deberta_finetuned_pii\", device=-1)\n",
    "\n",
    "# temp_text = \"My name is John and I live in California.\"\n",
    "temp_text = text_test\n",
    "output = gen(temp_text, aggregation_strategy=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "02ab4772-72f5-4f93-b205-932adab5c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Meet Jane Doe, a brilliant student at XYZ University. She can be reached at jane.doe@email.com or through her phone number +1234567890. Jane resides at 123 Main Street, Cityville. Her student ID is 987654 and her personal website is www.janedoe.com. Connect with her on social media using the username @janedoe.\\n\\nMeanwhile, John Smith, another outstanding student, can be contacted at john.smith@email.com or at +9876543210. John lives at 456 Oak Avenue, Townsville. His student ID is 123456, and you can visit his personal blog at www.johnsmithblog.com. Follow him on Twitter with the handle @johnsmith123.\\n\\nFor any inquiries about the university's programs, you can contact the administration office at admin@xyzuniversity.edu or call +5551234567. The office is located at 789 University Boulevard.\\n\\nVisit our official website at www.xyzuniversity.edu for more information on courses and admission procedures.\\n\\n\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "385656e4-6eda-49ac-80fa-de998a59b229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ZIPCODE',\n",
       "  'score': 0.59201986,\n",
       "  'word': ' 123456,',\n",
       "  'start': 484,\n",
       "  'end': 492},\n",
       " {'entity_group': 'URL',\n",
       "  'score': 0.72377163,\n",
       "  'word': ' www.johnsmithblog.com.',\n",
       "  'start': 531,\n",
       "  'end': 554},\n",
       " {'entity_group': 'EMAIL',\n",
       "  'score': 0.9881231,\n",
       "  'word': ' admin@xyzuniversity.edu',\n",
       "  'start': 704,\n",
       "  'end': 728},\n",
       " {'entity_group': 'PHONE_NUMBER',\n",
       "  'score': 0.9487186,\n",
       "  'word': ' +5551234567.',\n",
       "  'start': 736,\n",
       "  'end': 749},\n",
       " {'entity_group': 'STREETADDRESS',\n",
       "  'score': 0.9893532,\n",
       "  'word': ' 789 University Boulevard.\\n\\nVisit',\n",
       "  'start': 774,\n",
       "  'end': 807},\n",
       " {'entity_group': 'URL',\n",
       "  'score': 0.9544076,\n",
       "  'word': ' www.xyzuniversity.edu',\n",
       "  'start': 831,\n",
       "  'end': 853}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f70007e0-ad28-4e51-9b6d-3e0839cb372b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9719028-c4db-4237-ba45-b8f12abb9240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'your', 'original', 'sentence', 'here', '.', '[SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7c66a05-870f-4a9d-bd08-7a76171b2699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c55fc38a-9e5d-4dea-b7e7-c5afc13016da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'ĠDesign',\n",
       " 'ĠThinking',\n",
       " 'Ġfor',\n",
       " 'Ġinnovation',\n",
       " 'Ġreflex',\n",
       " 'ion',\n",
       " '-',\n",
       " 'Av',\n",
       " 'ril',\n",
       " 'Ġ2021',\n",
       " '-',\n",
       " 'N',\n",
       " 'ath',\n",
       " 'al',\n",
       " 'ie',\n",
       " 'ĠSy',\n",
       " 'lla',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Chall',\n",
       " 'enge',\n",
       " 'Ġ&',\n",
       " 'Ġselection',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'The',\n",
       " 'Ġtool',\n",
       " 'ĠI',\n",
       " 'Ġuse',\n",
       " 'Ġto',\n",
       " 'Ġhelp',\n",
       " 'Ġall',\n",
       " 'Ġstakeholders',\n",
       " 'Ġfinding',\n",
       " 'Ġtheir',\n",
       " 'Ġway',\n",
       " 'Ġthrough',\n",
       " 'Ġthe',\n",
       " 'Ġcomplexity',\n",
       " 'Ġof',\n",
       " 'Ġa',\n",
       " 'Ġproject',\n",
       " 'Ġis',\n",
       " 'Ġthe',\n",
       " 'Ġ',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'What',\n",
       " 'Ġexactly',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " '?',\n",
       " 'ĠAccording',\n",
       " 'Ġto',\n",
       " 'Ġthe',\n",
       " 'Ġdefinition',\n",
       " 'Ġof',\n",
       " 'ĠBu',\n",
       " 'zan',\n",
       " 'ĠT',\n",
       " '.',\n",
       " 'Ġand',\n",
       " 'ĠBu',\n",
       " 'zan',\n",
       " 'ĠB',\n",
       " '.',\n",
       " 'Ġ(',\n",
       " '1999',\n",
       " ',',\n",
       " 'ĠD',\n",
       " 'ess',\n",
       " 'ine',\n",
       " '-',\n",
       " 'mo',\n",
       " 'i',\n",
       " 'Ġ',\n",
       " 'Ġl',\n",
       " \"'\",\n",
       " 'intelligence',\n",
       " '.',\n",
       " 'ĠParis',\n",
       " ':',\n",
       " 'ĠLes',\n",
       " 'ĠÃī',\n",
       " 'd',\n",
       " 'itions',\n",
       " 'Ġd',\n",
       " \"'\",\n",
       " 'Organ',\n",
       " 'isation',\n",
       " '.),',\n",
       " 'Ġthe',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " 'Ġ(',\n",
       " 'or',\n",
       " 'Ġhe',\n",
       " 'uristic',\n",
       " 'Ġdiagram',\n",
       " ')',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġgraphic',\n",
       " 'Ġ',\n",
       " 'Ġrepresentation',\n",
       " 'Ġtechnique',\n",
       " 'Ġthat',\n",
       " 'Ġfollows',\n",
       " 'Ġthe',\n",
       " 'Ġnatural',\n",
       " 'Ġfunctioning',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġmind',\n",
       " 'Ġand',\n",
       " 'Ġallows',\n",
       " 'Ġthe',\n",
       " 'Ġbrain',\n",
       " \"'s\",\n",
       " 'Ġ',\n",
       " 'Ġpotential',\n",
       " 'Ġto',\n",
       " 'Ġbe',\n",
       " 'Ġreleased',\n",
       " '.',\n",
       " 'ĠCf',\n",
       " 'ĠAnnex',\n",
       " '1',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'This',\n",
       " 'Ġtool',\n",
       " 'Ġhas',\n",
       " 'Ġmany',\n",
       " 'Ġadvantages',\n",
       " ':',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġis',\n",
       " 'Ġaccessible',\n",
       " 'Ġto',\n",
       " 'Ġall',\n",
       " 'Ġand',\n",
       " 'Ġdoes',\n",
       " 'Ġnot',\n",
       " 'Ġrequire',\n",
       " 'Ġsignificant',\n",
       " 'Ġmaterial',\n",
       " 'Ġinvestment',\n",
       " 'Ġand',\n",
       " 'Ġcan',\n",
       " 'Ġbe',\n",
       " 'Ġdone',\n",
       " 'Ġ',\n",
       " 'Ġquickly',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġis',\n",
       " 'Ġscalable',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġallows',\n",
       " 'Ġcategor',\n",
       " 'ization',\n",
       " 'Ġand',\n",
       " 'Ġlinking',\n",
       " 'Ġof',\n",
       " 'Ġinformation',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġcan',\n",
       " 'Ġbe',\n",
       " 'Ġapplied',\n",
       " 'Ġto',\n",
       " 'Ġany',\n",
       " 'Ġtype',\n",
       " 'Ġof',\n",
       " 'Ġsituation',\n",
       " ':',\n",
       " 'Ġnot',\n",
       " 'et',\n",
       " 'aking',\n",
       " ',',\n",
       " 'Ġproblem',\n",
       " 'Ġsolving',\n",
       " ',',\n",
       " 'Ġanalysis',\n",
       " ',',\n",
       " 'Ġcreation',\n",
       " 'Ġof',\n",
       " 'Ġ',\n",
       " 'Ġnew',\n",
       " 'Ġideas',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġis',\n",
       " 'Ġsuitable',\n",
       " 'Ġfor',\n",
       " 'Ġall',\n",
       " 'Ġpeople',\n",
       " 'Ġand',\n",
       " 'Ġis',\n",
       " 'Ġeasy',\n",
       " 'Ġto',\n",
       " 'Ġlearn',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġis',\n",
       " 'Ġfun',\n",
       " 'Ġand',\n",
       " 'Ġencourages',\n",
       " 'Ġexchanges',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġmakes',\n",
       " 'Ġvisible',\n",
       " 'Ġthe',\n",
       " 'Ġdimension',\n",
       " 'Ġof',\n",
       " 'Ġprojects',\n",
       " ',',\n",
       " 'Ġopportunities',\n",
       " ',',\n",
       " 'Ġinter',\n",
       " 'connect',\n",
       " 'ions',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġsynthes',\n",
       " 'izes',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġmakes',\n",
       " 'Ġthe',\n",
       " 'Ġproject',\n",
       " 'Ġunderstandable',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'âĢ¢',\n",
       " 'Ġ',\n",
       " 'ĠIt',\n",
       " 'Ġallows',\n",
       " 'Ġyou',\n",
       " 'Ġto',\n",
       " 'Ġexplore',\n",
       " 'Ġideas',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'The',\n",
       " 'Ġcreation',\n",
       " 'Ġof',\n",
       " 'Ġa',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " 'Ġstarts',\n",
       " 'Ġwith',\n",
       " 'Ġan',\n",
       " 'Ġidea',\n",
       " '/',\n",
       " 'problem',\n",
       " 'Ġlocated',\n",
       " 'Ġat',\n",
       " 'Ġits',\n",
       " 'Ġcenter',\n",
       " '.',\n",
       " 'ĠThis',\n",
       " 'Ġstarting',\n",
       " 'Ġpoint',\n",
       " 'Ġ',\n",
       " 'Ġgenerates',\n",
       " 'Ġideas',\n",
       " '/',\n",
       " 'work',\n",
       " 'Ġareas',\n",
       " ',',\n",
       " 'Ġincre',\n",
       " 'mented',\n",
       " 'Ġaround',\n",
       " 'Ġthis',\n",
       " 'Ġcenter',\n",
       " 'Ġin',\n",
       " 'Ġa',\n",
       " 'Ġradial',\n",
       " 'Ġstructure',\n",
       " ',',\n",
       " 'Ġwhich',\n",
       " 'Ġin',\n",
       " 'Ġturn',\n",
       " 'Ġis',\n",
       " 'Ġ',\n",
       " 'Ġcompleted',\n",
       " 'Ġwith',\n",
       " 'Ġas',\n",
       " 'Ġmany',\n",
       " 'Ġbranches',\n",
       " 'Ġas',\n",
       " 'Ġnew',\n",
       " 'Ġideas',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'This',\n",
       " 'Ġtool',\n",
       " 'Ġenables',\n",
       " 'Ġcreativity',\n",
       " 'Ġand',\n",
       " 'Ġlogic',\n",
       " 'Ġto',\n",
       " 'Ġbe',\n",
       " 'Ġmobilized',\n",
       " ',',\n",
       " 'Ġit',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġmap',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġthoughts',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Creat',\n",
       " 'ivity',\n",
       " 'Ġis',\n",
       " 'Ġenhanced',\n",
       " 'Ġbecause',\n",
       " 'Ġparticipants',\n",
       " 'Ġfeel',\n",
       " 'Ġcomfortable',\n",
       " 'Ġwith',\n",
       " 'Ġthe',\n",
       " 'Ġmethod',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Application',\n",
       " 'Ġ&',\n",
       " 'ĠInsight',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'I',\n",
       " 'Ġstart',\n",
       " 'Ġthe',\n",
       " 'Ġprocess',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " 'Ġcreation',\n",
       " 'Ġwith',\n",
       " 'Ġthe',\n",
       " 'Ġstakeholders',\n",
       " 'Ġstanding',\n",
       " 'Ġaround',\n",
       " 'Ġa',\n",
       " 'Ġlarge',\n",
       " 'Ġboard',\n",
       " 'Ġ',\n",
       " 'Ġ(',\n",
       " 'white',\n",
       " 'Ġor',\n",
       " 'Ġpaper',\n",
       " 'Ġboard',\n",
       " ').',\n",
       " 'ĠIn',\n",
       " 'Ġthe',\n",
       " 'Ġcenter',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġboard',\n",
       " ',',\n",
       " 'ĠI',\n",
       " 'Ġwrite',\n",
       " 'Ġand',\n",
       " 'Ġhighlight',\n",
       " 'Ġthe',\n",
       " 'Ġtopic',\n",
       " 'Ġto',\n",
       " 'Ġdesign',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Through',\n",
       " 'Ġa',\n",
       " 'Ġseries',\n",
       " 'Ġof',\n",
       " 'Ġquestions',\n",
       " ',',\n",
       " 'ĠI',\n",
       " 'Ġguide',\n",
       " 'Ġthe',\n",
       " 'Ġstakeholders',\n",
       " 'Ġin',\n",
       " 'Ġmodelling',\n",
       " 'Ġthe',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " '.',\n",
       " 'ĠI',\n",
       " 'Ġadapt',\n",
       " 'Ġthe',\n",
       " 'Ġseries',\n",
       " 'Ġ',\n",
       " 'Ġof',\n",
       " 'Ġquestions',\n",
       " 'Ġaccording',\n",
       " 'Ġto',\n",
       " 'Ġthe',\n",
       " 'Ġtopic',\n",
       " 'Ġto',\n",
       " 'Ġbe',\n",
       " 'Ġaddressed',\n",
       " '.',\n",
       " 'ĠIn',\n",
       " 'Ġthe',\n",
       " 'Ġtype',\n",
       " 'Ġof',\n",
       " 'Ġquestions',\n",
       " ',',\n",
       " 'Ġwe',\n",
       " 'Ġcan',\n",
       " 'Ġuse',\n",
       " ':',\n",
       " 'Ġwho',\n",
       " ',',\n",
       " 'Ġwhat',\n",
       " ',',\n",
       " 'Ġ',\n",
       " 'Ġwhen',\n",
       " ',',\n",
       " 'Ġwhere',\n",
       " ',',\n",
       " 'Ġwhy',\n",
       " ',',\n",
       " 'Ġhow',\n",
       " ',',\n",
       " 'Ġhow',\n",
       " 'Ġmuch',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'The',\n",
       " 'Ġuse',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'ĠâĢ',\n",
       " 'ľ',\n",
       " 'why',\n",
       " 'âĢ',\n",
       " 'Ŀ',\n",
       " 'Ġis',\n",
       " 'Ġvery',\n",
       " 'Ġinteresting',\n",
       " 'Ġto',\n",
       " 'Ġunderstand',\n",
       " 'Ġthe',\n",
       " 'Ġorigin',\n",
       " '.',\n",
       " 'ĠBy',\n",
       " 'Ġthis',\n",
       " 'Ġway',\n",
       " ',',\n",
       " 'Ġthe',\n",
       " 'Ġinterviewed',\n",
       " 'Ġperson',\n",
       " 'Ġ',\n",
       " 'Ġfre',\n",
       " 'es',\n",
       " 'Ġitself',\n",
       " 'Ġfrom',\n",
       " 'Ġparad',\n",
       " 'ig',\n",
       " 'ms',\n",
       " 'Ġand',\n",
       " 'Ġthus',\n",
       " 'Ġd',\n",
       " 'ares',\n",
       " 'Ġto',\n",
       " 'Ġpropose',\n",
       " 'Ġnew',\n",
       " 'Ġideas',\n",
       " 'Ġ/',\n",
       " 'Ġways',\n",
       " 'Ġof',\n",
       " 'Ġfunctioning',\n",
       " '.',\n",
       " 'ĠI',\n",
       " 'Ġplan',\n",
       " 'Ġtwo',\n",
       " 'Ġ',\n",
       " 'Ġhours',\n",
       " 'Ġfor',\n",
       " 'Ġa',\n",
       " 'Ġworkshop',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Design',\n",
       " 'ĠThinking',\n",
       " 'Ġfor',\n",
       " 'Ġinnovation',\n",
       " 'Ġreflex',\n",
       " 'ion',\n",
       " '-',\n",
       " 'Av',\n",
       " 'ril',\n",
       " 'Ġ2021',\n",
       " '-',\n",
       " 'N',\n",
       " 'ath',\n",
       " 'al',\n",
       " 'ie',\n",
       " 'ĠSy',\n",
       " 'lla',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'After',\n",
       " 'Ġmodelling',\n",
       " 'Ġthe',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " 'Ġon',\n",
       " 'Ġpaper',\n",
       " ',',\n",
       " 'ĠI',\n",
       " 'Ġpropose',\n",
       " 'Ġto',\n",
       " 'Ġthe',\n",
       " 'Ġparticipants',\n",
       " 'Ġa',\n",
       " 'Ġdigital',\n",
       " 'Ġvisualization',\n",
       " 'Ġof',\n",
       " 'Ġtheir',\n",
       " 'Ġ',\n",
       " 'Ġwork',\n",
       " 'Ġwith',\n",
       " 'Ġthe',\n",
       " 'Ġaddition',\n",
       " 'Ġof',\n",
       " 'Ġcolor',\n",
       " 'Ġcodes',\n",
       " ',',\n",
       " 'Ġimages',\n",
       " 'Ġand',\n",
       " 'Ġinter',\n",
       " 'connect',\n",
       " 'ions',\n",
       " '.',\n",
       " 'ĠThis',\n",
       " 'Ġsecond',\n",
       " 'Ġworkshop',\n",
       " 'Ġalso',\n",
       " 'Ġlasts',\n",
       " 'Ġ',\n",
       " 'Ġtwo',\n",
       " 'Ġhours',\n",
       " 'Ġand',\n",
       " 'Ġallows',\n",
       " 'Ġthe',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " 'Ġto',\n",
       " 'Ġevolve',\n",
       " '.',\n",
       " 'ĠOnce',\n",
       " 'Ġfamiliar',\n",
       " 'ized',\n",
       " 'Ġwith',\n",
       " 'Ġit',\n",
       " ',',\n",
       " 'Ġthe',\n",
       " 'Ġstakeholders',\n",
       " 'Ġdiscover',\n",
       " 'Ġ',\n",
       " 'Ġthe',\n",
       " 'Ġpower',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġtool',\n",
       " '.',\n",
       " 'ĠThen',\n",
       " ',',\n",
       " 'Ġthe',\n",
       " 'Ġsecond',\n",
       " 'Ġworkshop',\n",
       " 'Ġbrings',\n",
       " 'Ġout',\n",
       " 'Ġeven',\n",
       " 'Ġmore',\n",
       " 'Ġideas',\n",
       " 'Ġand',\n",
       " 'Ġconstructive',\n",
       " 'Ġ',\n",
       " 'Ġexchanges',\n",
       " 'Ġbetween',\n",
       " 'Ġthe',\n",
       " 'Ġstakeholders',\n",
       " '.',\n",
       " 'ĠAround',\n",
       " 'Ġthis',\n",
       " 'Ġnew',\n",
       " 'Ġmind',\n",
       " 'Ġmap',\n",
       " ',',\n",
       " 'Ġthey',\n",
       " 'Ġhave',\n",
       " 'Ġlearned',\n",
       " 'Ġto',\n",
       " 'Ġwork',\n",
       " 'Ġ',\n",
       " 'Ġtogether',\n",
       " 'Ġand',\n",
       " 'Ġwant',\n",
       " 'Ġto',\n",
       " 'Ġmake',\n",
       " 'Ġvisible',\n",
       " 'Ġthe',\n",
       " 'Ġuntold',\n",
       " 'Ġideas',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'I',\n",
       " 'Ġnow',\n",
       " 'Ġpresent',\n",
       " 'Ġall',\n",
       " 'Ġthe',\n",
       " 'Ġprojects',\n",
       " 'ĠI',\n",
       " 'Ġmanage',\n",
       " 'Ġin',\n",
       " 'Ġthis',\n",
       " 'Ġtype',\n",
       " 'Ġof',\n",
       " 'Ġformat',\n",
       " 'Ġin',\n",
       " 'Ġorder',\n",
       " 'Ġto',\n",
       " 'Ġease',\n",
       " 'Ġrapid',\n",
       " 'Ġunderstanding',\n",
       " 'Ġfor',\n",
       " 'Ġ',\n",
       " 'Ġdecision',\n",
       " '-',\n",
       " 'makers',\n",
       " '.',\n",
       " 'ĠThese',\n",
       " 'Ġpresentations',\n",
       " 'Ġare',\n",
       " 'Ġthe',\n",
       " 'Ġcore',\n",
       " 'Ġof',\n",
       " 'Ġmy',\n",
       " 'Ġbusiness',\n",
       " 'Ġmodels',\n",
       " '.',\n",
       " 'ĠThe',\n",
       " 'Ġdecision',\n",
       " '-',\n",
       " 'makers',\n",
       " 'Ġare',\n",
       " 'Ġ',\n",
       " 'Ġthus',\n",
       " 'Ġable',\n",
       " 'Ġto',\n",
       " 'Ġidentify',\n",
       " 'Ġthe',\n",
       " 'Ġopportunities',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġprojects',\n",
       " 'Ġand',\n",
       " 'Ġcan',\n",
       " 'Ġtake',\n",
       " 'Ġquick',\n",
       " 'Ġdecisions',\n",
       " 'Ġto',\n",
       " 'Ġvalidate',\n",
       " 'Ġthem',\n",
       " '.',\n",
       " 'Ġ',\n",
       " 'ĠThey',\n",
       " 'Ġfind',\n",
       " 'Ġanswers',\n",
       " 'Ġto',\n",
       " 'Ġtheir',\n",
       " 'Ġquestions',\n",
       " 'Ġthank',\n",
       " 'Ġto',\n",
       " 'Ġa',\n",
       " 'Ġschematic',\n",
       " 'Ġrepresentation',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'App',\n",
       " 'roach',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'What',\n",
       " 'ĠI',\n",
       " 'Ġfind',\n",
       " 'Ġamazing',\n",
       " 'Ġwith',\n",
       " 'Ġthe',\n",
       " 'Ġfac',\n",
       " 'ilitation',\n",
       " 'Ġof',\n",
       " 'Ġthis',\n",
       " 'Ġtype',\n",
       " 'Ġof',\n",
       " 'Ġworkshop',\n",
       " 'Ġis',\n",
       " 'Ġthe',\n",
       " 'Ġparticipants',\n",
       " 'Ġcommitment',\n",
       " 'Ġfor',\n",
       " 'Ġ',\n",
       " 'Ġthe',\n",
       " 'Ġproject',\n",
       " '.',\n",
       " 'ĠThis',\n",
       " 'Ġtool',\n",
       " 'Ġhelps',\n",
       " 'Ġto',\n",
       " 'Ġgive',\n",
       " 'Ġmeaning',\n",
       " '.',\n",
       " 'ĠThe',\n",
       " 'Ġparticipants',\n",
       " 'Ġappropriate',\n",
       " 'Ġthe',\n",
       " 'Ġstory',\n",
       " 'Ġand',\n",
       " 'Ġwant',\n",
       " 'Ġto',\n",
       " 'Ġkeep',\n",
       " 'Ġ',\n",
       " 'Ġwriting',\n",
       " 'Ġit',\n",
       " '.',\n",
       " 'ĠThen',\n",
       " ',',\n",
       " 'Ġthey',\n",
       " 'Ġeasily',\n",
       " 'Ġbecome',\n",
       " 'Ġactors',\n",
       " 'Ġor',\n",
       " 'Ġsponsors',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġproject',\n",
       " '.',\n",
       " 'ĠA',\n",
       " 'Ġtrust',\n",
       " 'Ġrelationship',\n",
       " 'Ġis',\n",
       " 'Ġbuilt',\n",
       " ',',\n",
       " 'Ġ',\n",
       " 'Ġthus',\n",
       " 'Ġfacilitating',\n",
       " 'Ġthe',\n",
       " 'Ġimplementation',\n",
       " 'Ġof',\n",
       " 'Ġrelated',\n",
       " 'Ġactions',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Design',\n",
       " 'ĠThinking',\n",
       " 'Ġfor',\n",
       " 'Ġinnovation',\n",
       " 'Ġreflex',\n",
       " 'ion',\n",
       " '-',\n",
       " 'Av',\n",
       " 'ril',\n",
       " 'Ġ2021',\n",
       " '-',\n",
       " 'N',\n",
       " 'ath',\n",
       " 'al',\n",
       " 'ie',\n",
       " 'ĠSy',\n",
       " 'lla',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'An',\n",
       " 'nex',\n",
       " 'Ġ1',\n",
       " ':',\n",
       " 'ĠMind',\n",
       " 'ĠMap',\n",
       " 'ĠShared',\n",
       " 'Ġfacilities',\n",
       " 'Ġproject',\n",
       " 'ĊĊ',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad5c0b9-fec6-439a-9ba3-6d44f6f36ce6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'O',\n",
       " 'I-FIRSTNAME',\n",
       " 'O',\n",
       " 'B-FIRSTNAME',\n",
       " 'I-COMPANY_NAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-MIDDLENAME',\n",
       " 'B-MIDDLENAME',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'O',\n",
       " 'I-FIRSTNAME',\n",
       " 'I-FIRSTNAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'O',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-MIDDLENAME',\n",
       " 'B-FIRSTNAME',\n",
       " 'B-MIDDLENAME',\n",
       " 'B-MIDDLENAME',\n",
       " 'B-MIDDLENAME',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tokens_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee6d94-7886-4060-9246-98068ad280cc",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07c3d7-42f0-40fb-826f-17268aad733a",
   "metadata": {},
   "source": [
    "## Spacy tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a91043-1ab9-4b8b-9662-faf37bf6b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text to tokenize\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "\n",
    "# Tokenize the text using spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Reconstruct the original text\n",
    "reconstructed_text = ''.join(token.text_with_ws for token in doc)\n",
    "\n",
    "print(reconstructed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85128ec8-dfc2-4e2e-a1ae-444e523179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join([token.text + token.whitespace_  for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45626d48-59f8-41c4-a7a6-059d2099e8cd",
   "metadata": {},
   "source": [
    "# Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a074677-0543-4466-9739-ce18d76dcb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "def ner_pipeline(text):\n",
    "    # Load pre-trained BERT model and tokenizer for token classification\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the text using the model's tokenizer\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted labels\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "    # Convert predicted labels to list\n",
    "    predicted_labels = predictions[0].tolist()\n",
    "\n",
    "    # Align the predicted labels to the original words\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    words = tokenizer.convert_tokens_to_string(tokens).split()\n",
    "\n",
    "    # Create a list of tuples (word, predicted_label)\n",
    "    word_label_pairs = list(zip(words, predicted_labels))\n",
    "\n",
    "    return word_label_pairs\n",
    "\n",
    "# # Example usage\n",
    "# text = \"Named Entity Recognition with BERT is great!\"\n",
    "# result = ner_pipeline(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fc596-70c1-4117-b2d1-3615db341ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "text = \"Named Entity Recognition with BERT is great Sylvian!\"\n",
    "# Load pre-trained BERT model and tokenizer for token classification\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the text using the model's tokenizer\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the predicted labels\n",
    "predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "# Convert predicted labels to list\n",
    "predicted_labels = predictions[0].tolist()\n",
    "\n",
    "# Align the predicted labels to the original words\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "words = tokenizer.convert_tokens_to_string(tokens).split()\n",
    "\n",
    "# Create a list of tuples (word, predicted_label)\n",
    "word_label_pairs = list(zip(words, predicted_labels))\n",
    "\n",
    "# # Example usage\n",
    "\n",
    "# result = ner_pipeline(text)\n",
    "print(word_label_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac73a29e-2113-4a66-bcc1-3d431452aa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " 'with',\n",
       " 'bert',\n",
       " 'is',\n",
       " 'great',\n",
       " 'sylvia',\n",
       " '##n',\n",
       " '!',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "037f3615-9159-4743-b30a-662368f0a80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c948e34d-6be6-4cbe-bea0-b48c87002a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa507454-428a-4b10-8e73-d0fc93ea2623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20fabdd7-c602-4398-b52d-12d9f25427a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee9a13c7-a835-4d4c-83d0-bd228373b315",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tokens() is not available when using non-fast tokenizers (e.g. instance of a `XxxTokenizerFast` class).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:313\u001b[0m, in \u001b[0;36mBatchEncoding.tokens\u001b[1;34m(self, batch_index)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03mReturn the list of tokens (sub-parts of the input strings after word/subword splitting and before conversion to\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03minteger indices) at a given batch index (only works for the output of a fast tokenizer).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    `List[str]`: The list of tokens at that index.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens() is not available when using non-fast tokenizers (e.g. instance of a `XxxTokenizerFast`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m     )\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings[batch_index]\u001b[38;5;241m.\u001b[39mtokens\n",
      "\u001b[1;31mValueError\u001b[0m: tokens() is not available when using non-fast tokenizers (e.g. instance of a `XxxTokenizerFast` class)."
     ]
    }
   ],
   "source": [
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449b047-7c20-4eba-9335-1fe9a11f8516",
   "metadata": {},
   "source": [
    "## Token Limit (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa528ba-1cbc-4c81-8e33-e89e13f5ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = df_train.loc[0].full_text\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(full_text)\n",
    "text = ''.join([token.text_with_ws for token in doc[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a0cf541-6730-49cc-8ce8-fa7875ed5c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nChallenge & selection\\n\\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\\n\\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46961d7-61ea-4554-b4a4-376729f8bbd4",
   "metadata": {},
   "source": [
    "## Highest non-O probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aba226-9a59-44bb-a383-f6272489a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_non_O_labels_threshold(tokens, predicted_labels, label_probabilities, threshold=0.5):\n",
    "    highest_non_O_labels = []\n",
    "\n",
    "    for token, label_ids, probabilities in zip(tokens, predicted_labels, label_probabilities):\n",
    "        labels = [model.config.id2label[label_id] for label_id in label_ids]\n",
    "        non_O_labels = []\n",
    "        non_O_probabilities = []\n",
    "\n",
    "        # Iterate through predicted labels and their probabilities\n",
    "        for label, probability in zip(labels, probabilities):\n",
    "            # Exclude 'O' labels and labels with probabilities below the threshold\n",
    "            if label != 'O' and probability >= threshold:\n",
    "                non_O_labels.append(label)\n",
    "                non_O_probabilities.append(probability)\n",
    "\n",
    "        # If there are non-'O' labels above the threshold, select the one with the highest probability\n",
    "        if non_O_labels:\n",
    "            highest_non_O_label = non_O_labels[non_O_probabilities.index(max(non_O_probabilities))]\n",
    "            highest_non_O_labels.append((token, highest_non_O_label))\n",
    "        else:\n",
    "            # If all labels are 'O' or below the threshold, consider it as non-entity\n",
    "            highest_non_O_labels.append((token, 'O'))\n",
    "\n",
    "    return highest_non_O_labels\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05623c0-2c9b-4958-b0e9-fac209980385",
   "metadata": {},
   "source": [
    "## Prediction Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22829e-abfe-4afc-a54f-9e29f0a63641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "import spacy\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer using Auto classes\n",
    "model_name = \"lakshyakh93/deberta_finetuned_pii\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load spaCy model for tokenization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "# text = \"John Smith works at OpenAI in San Francisco.\"\n",
    "\n",
    "# text = df_train.loc[0].full_text\n",
    "# text = text\n",
    "text = text_test\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Step 1: Tokenize the text using spaCy for words\n",
    "words = [token.text for token in doc]\n",
    "\n",
    "# Step 2: Tokenize the text using the model's tokenizer and get word to subword mapping\n",
    "# inputs = tokenizer(text, return_tensors='pt', return_offsets_mapping=False)\n",
    "inputs = tokenizer(words, return_tensors='pt', return_offsets_mapping=False, is_split_into_words=True)\n",
    "word_ids = inputs.word_ids()\n",
    "\n",
    "# Step 3: Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "\n",
    "# Step 4: Create a list of which tokens or subwords correspond to a word using the word_ids variable\n",
    "word_subword_mapping = {}\n",
    "for i, word_id in enumerate(word_ids):\n",
    "    if word_id is not None:\n",
    "        if word_id not in word_subword_mapping:\n",
    "            word_subword_mapping[word_id] = []\n",
    "        word_subword_mapping[word_id].append(i)\n",
    "\n",
    "# Instantiate predictions variable\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "\n",
    "# Step 5: Iterate through pairs of words and subwords to count the majority label\n",
    "word_labels = []\n",
    "for word_id, subword_indices in word_subword_mapping.items():\n",
    "    subword_labels = predictions[0, subword_indices]\n",
    "    majority_label = torch.mode(subword_labels).values.item()\n",
    "    word_labels.append((words[word_id], model.config.id2label[majority_label]))\n",
    "\n",
    "# Display results\n",
    "# print(\"Original Text:\", text)\n",
    "# print(\"Word Labels:\", word_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "060eafb8-937e-4d2b-b088-58975073d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_probabilities = torch.softmax(outputs, dim=2)[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a3273b8-8bc3-4648-a172-28950994b0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_probabilities[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a2d75b-8f9f-4d82-92f1-536103488fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.9995e-01,  7.0126e-01,  6.4311e-01,  2.6335e-01,  8.8299e-01,\n",
       "         4.3662e-01,  7.0182e-01,  4.0063e+00,  7.9710e-01, -2.3113e-02,\n",
       "         2.4447e-01, -2.1183e-01, -3.6750e-01,  1.4272e+00, -7.0485e-01,\n",
       "        -1.2629e-01, -2.1296e-01, -5.5472e-02, -3.4729e-01,  7.6680e-02,\n",
       "        -5.6008e-01, -7.2453e-01, -8.7485e-01,  2.6355e-01, -4.3632e-01,\n",
       "        -4.6025e-02, -3.5645e-01, -7.4701e-01, -8.6652e-01, -7.8131e-01,\n",
       "        -1.2693e+00, -5.5256e-01, -4.4496e-01,  1.9675e-01, -1.2938e+00,\n",
       "        -7.4463e-01, -4.8393e-01,  4.2690e-01,  5.4200e-01,  2.0513e-01,\n",
       "        -3.3553e-03,  4.3093e-01, -5.1900e-01, -4.4200e-01, -8.3023e-01,\n",
       "        -8.0837e-01, -1.4081e+00, -8.1950e-01, -1.1582e+00, -2.8280e-01,\n",
       "         1.3150e-01,  3.8448e-02, -1.0471e+00, -5.3441e-01,  2.4152e-04,\n",
       "         4.7095e-02, -1.3062e+00, -1.2903e+00,  2.4801e-01,  1.1354e+00,\n",
       "        -2.8463e-01,  6.2392e-01, -5.0984e-01, -4.8388e-01, -7.3426e-01,\n",
       "         2.1283e-02,  3.7291e-02,  6.6526e-02,  9.2303e-01, -2.4366e-01,\n",
       "        -6.9283e-02,  8.3983e-02, -6.3133e-01, -9.4704e-01, -2.1881e-01,\n",
       "         8.2676e-02, -8.0442e-01, -6.6553e-01, -7.0915e-01,  2.4109e-01,\n",
       "        -4.8190e-02, -8.3114e-01, -1.2683e-01, -6.2635e-01, -1.4231e-01,\n",
       "         3.7135e-01, -7.7888e-01,  6.1220e-02,  1.3569e-01, -9.8949e-01,\n",
       "         1.3054e-02, -8.1744e-01, -1.1811e+00,  4.1480e-01, -5.4848e-01,\n",
       "         5.0983e-01,  3.2345e-03,  1.9789e-01, -2.5744e-01, -2.8186e-01,\n",
       "        -1.1771e-02, -1.6789e-01, -3.4921e-01,  1.0399e+00,  2.1262e-01,\n",
       "        -1.0721e-01, -7.0364e-01, -6.8454e-01,  6.0880e-01, -1.0015e-01,\n",
       "        -8.8881e-01, -1.2533e+00, -8.1372e-01, -4.4325e-01, -5.4939e-01,\n",
       "        -1.8390e+00], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e72c465-6c75-4bf3-93b2-17a4aa83f809",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moutputs\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93f7b38f-d245-4d64-94f5-4de29e8ec271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "16220f23-eb6a-436e-9b95-20cd913f0faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'ĠDesign',\n",
       " 'ĠThinking',\n",
       " 'Ġfor',\n",
       " 'Ġinnovation',\n",
       " 'Ġreflex',\n",
       " 'ion',\n",
       " 'Ġ-',\n",
       " 'ĠAv',\n",
       " 'ril',\n",
       " 'Ġ2021',\n",
       " 'Ġ-',\n",
       " 'ĠNath',\n",
       " 'al',\n",
       " 'ie',\n",
       " 'ĠSy',\n",
       " 'lla',\n",
       " 'Ġ',\n",
       " 'ĊĊ',\n",
       " 'ĠChallenge']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68603017-9040-437a-a9f7-964cb758faa9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Design', 'O'),\n",
       " ('Thinking', 'O'),\n",
       " ('for', 'O'),\n",
       " ('innovation', 'O'),\n",
       " ('reflexion', 'B-FIRSTNAME'),\n",
       " ('-', 'O'),\n",
       " ('Avril', 'I-FIRSTNAME'),\n",
       " ('2021', 'B-NUMBER'),\n",
       " ('-', 'I-NUMBER'),\n",
       " ('Nathalie', 'I-NUMBER'),\n",
       " ('Sylla', 'I-NUMBER'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('Challenge', 'O'),\n",
       " ('&', 'O'),\n",
       " ('selection', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('The', 'O'),\n",
       " ('tool', 'O'),\n",
       " ('I', 'O'),\n",
       " ('use', 'O'),\n",
       " ('to', 'O'),\n",
       " ('help', 'O'),\n",
       " ('all', 'O'),\n",
       " ('stakeholders', 'O'),\n",
       " ('finding', 'O'),\n",
       " ('their', 'O'),\n",
       " ('way', 'O'),\n",
       " ('through', 'O'),\n",
       " ('the', 'O'),\n",
       " ('complexity', 'O'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('project', 'O'),\n",
       " ('is', 'O'),\n",
       " ('the', 'O'),\n",
       " (' ', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('What', 'O'),\n",
       " ('exactly', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('?', 'O'),\n",
       " ('According', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('definition', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Buzan', 'O'),\n",
       " ('T.', 'O'),\n",
       " ('and', 'O'),\n",
       " ('Buzan', 'O'),\n",
       " ('B.', 'O'),\n",
       " ('(', 'O'),\n",
       " ('1999', 'O'),\n",
       " (',', 'O'),\n",
       " ('Dessine', 'B-COMPANY_NAME'),\n",
       " ('-', 'I-COMPANY_NAME'),\n",
       " ('moi', 'I-COMPANY_NAME'),\n",
       " (' ', 'I-COMPANY_NAME'),\n",
       " (\"l'intelligence\", 'I-COMPANY_NAME'),\n",
       " ('.', 'O'),\n",
       " ('Paris', 'O'),\n",
       " (':', 'O'),\n",
       " ('Les', 'O'),\n",
       " ('Éditions', 'O'),\n",
       " (\"d'Organisation\", 'O'),\n",
       " ('.', 'O'),\n",
       " (')', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('(', 'O'),\n",
       " ('or', 'O'),\n",
       " ('heuristic', 'O'),\n",
       " ('diagram', 'O'),\n",
       " (')', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('graphic', 'O'),\n",
       " (' ', 'O'),\n",
       " ('representation', 'O'),\n",
       " ('technique', 'O'),\n",
       " ('that', 'O'),\n",
       " ('follows', 'O'),\n",
       " ('the', 'O'),\n",
       " ('natural', 'O'),\n",
       " ('functioning', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('and', 'O'),\n",
       " ('allows', 'O'),\n",
       " ('the', 'O'),\n",
       " ('brain', 'O')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "518bbc07-ded2-4db4-aa28-b1cdd1a913d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_tokens = 125 | len_pred = 125\n"
     ]
    }
   ],
   "source": [
    "print(f'len_tokens = {len(list_tokens)} | len_pred = {len(predictions[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9ac94f3-16a3-42f7-ba6b-d3f1dffb06b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7,   7,   7,   7,   7,   2,   2,   7,   3,   3, 107, 108, 108, 108,\n",
       "        108, 108, 108,   7,   7,   7])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b53a5ed-8667-412f-b24d-eb62ffafee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = [model.config.id2label[int(pred)] for pred in predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cef2cf8-720e-45ac-b6cc-a755033577a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 'O'),\n",
       " ('ĠDesign', 'O'),\n",
       " ('ĠThinking', 'O'),\n",
       " ('Ġfor', 'O'),\n",
       " ('Ġinnovation', 'O'),\n",
       " ('Ġreflex', 'B-FIRSTNAME'),\n",
       " ('ion', 'B-FIRSTNAME'),\n",
       " ('Ġ-', 'O'),\n",
       " ('ĠAv', 'I-FIRSTNAME'),\n",
       " ('ril', 'I-FIRSTNAME'),\n",
       " ('Ġ2021', 'B-NUMBER'),\n",
       " ('Ġ-', 'I-NUMBER'),\n",
       " ('ĠNath', 'I-NUMBER'),\n",
       " ('al', 'I-NUMBER'),\n",
       " ('ie', 'I-NUMBER'),\n",
       " ('ĠSy', 'I-NUMBER'),\n",
       " ('lla', 'I-NUMBER'),\n",
       " ('Ġ', 'O'),\n",
       " ('ĊĊ', 'O'),\n",
       " ('ĠChallenge', 'O'),\n",
       " ('Ġ&', 'O'),\n",
       " ('Ġselection', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('ĊĊ', 'O'),\n",
       " ('ĠThe', 'O'),\n",
       " ('Ġtool', 'O'),\n",
       " ('ĠI', 'O'),\n",
       " ('Ġuse', 'O'),\n",
       " ('Ġto', 'O'),\n",
       " ('Ġhelp', 'O'),\n",
       " ('Ġall', 'O'),\n",
       " ('Ġstakeholders', 'O'),\n",
       " ('Ġfinding', 'O'),\n",
       " ('Ġtheir', 'O'),\n",
       " ('Ġway', 'O'),\n",
       " ('Ġthrough', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġcomplexity', 'O'),\n",
       " ('Ġof', 'O'),\n",
       " ('Ġa', 'O'),\n",
       " ('Ġproject', 'O'),\n",
       " ('Ġis', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġmap', 'O'),\n",
       " ('Ġ.', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('ĊĊ', 'O'),\n",
       " ('ĠWhat', 'O'),\n",
       " ('Ġexactly', 'O'),\n",
       " ('Ġis', 'O'),\n",
       " ('Ġa', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġmap', 'O'),\n",
       " ('Ġ?', 'O'),\n",
       " ('ĠAccording', 'O'),\n",
       " ('Ġto', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġdefinition', 'O'),\n",
       " ('Ġof', 'O'),\n",
       " ('ĠBu', 'O'),\n",
       " ('zan', 'O'),\n",
       " ('ĠT', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Ġand', 'O'),\n",
       " ('ĠBu', 'O'),\n",
       " ('zan', 'O'),\n",
       " ('ĠB', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Ġ(', 'O'),\n",
       " ('Ġ1999', 'O'),\n",
       " ('Ġ,', 'O'),\n",
       " ('ĠD', 'B-COMPANY_NAME'),\n",
       " ('ess', 'B-COMPANY_NAME'),\n",
       " ('ine', 'B-COMPANY_NAME'),\n",
       " ('Ġ-', 'I-COMPANY_NAME'),\n",
       " ('Ġmo', 'I-COMPANY_NAME'),\n",
       " ('i', 'I-COMPANY_NAME'),\n",
       " ('Ġ', 'I-COMPANY_NAME'),\n",
       " ('Ġl', 'I-COMPANY_NAME'),\n",
       " (\"'\", 'I-COMPANY_NAME'),\n",
       " ('intelligence', 'I-COMPANY_NAME'),\n",
       " ('Ġ.', 'O'),\n",
       " ('ĠParis', 'O'),\n",
       " ('Ġ:', 'O'),\n",
       " ('ĠLes', 'O'),\n",
       " ('ĠÃī', 'O'),\n",
       " ('d', 'O'),\n",
       " ('itions', 'O'),\n",
       " ('Ġd', 'O'),\n",
       " (\"'\", 'O'),\n",
       " ('Organ', 'O'),\n",
       " ('isation', 'O'),\n",
       " ('Ġ.', 'O'),\n",
       " ('Ġ)', 'O'),\n",
       " ('Ġ,', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġmap', 'O'),\n",
       " ('Ġ(', 'O'),\n",
       " ('Ġor', 'O'),\n",
       " ('Ġhe', 'O'),\n",
       " ('uristic', 'O'),\n",
       " ('Ġdiagram', 'O'),\n",
       " ('Ġ)', 'O'),\n",
       " ('Ġis', 'O'),\n",
       " ('Ġa', 'O'),\n",
       " ('Ġgraphic', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('Ġrepresentation', 'O'),\n",
       " ('Ġtechnique', 'O'),\n",
       " ('Ġthat', 'O'),\n",
       " ('Ġfollows', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġnatural', 'O'),\n",
       " ('Ġfunctioning', 'O'),\n",
       " ('Ġof', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġand', 'O'),\n",
       " ('Ġallows', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġbrain', 'O'),\n",
       " ('[SEP]', 'O')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_labels = list(zip(list_tokens, pred_labels))\n",
    "token_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495b25d-cf34-47bd-89a2-60ef03fa5f22",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1cf6ee0d-2cd0-421d-87da-4b760f35692a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7,   7,   7,   7,   7,   2,   2,   7,   7,   7, 107,  19,  19,  19,\n",
       "         19,  19,   4,   4,   5,   7])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "409e63ed-eb70-4cbb-8641-b25a8f0ae09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = [model.config.id2label[int(pred)] for pred in predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2690350e-d0cc-4208-b271-36ced9d4edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 'O'),\n",
       " ('ĠDesign', 'O'),\n",
       " ('ĠThinking', 'O'),\n",
       " ('Ġfor', 'O'),\n",
       " ('Ġinnovation', 'O'),\n",
       " ('Ġreflex', 'B-FIRSTNAME'),\n",
       " ('ion', 'B-FIRSTNAME'),\n",
       " ('Ġ-', 'O'),\n",
       " ('ĠAv', 'O'),\n",
       " ('ril', 'O'),\n",
       " ('Ġ2021', 'B-NUMBER'),\n",
       " ('Ġ-', 'I-DATE'),\n",
       " ('ĠNath', 'I-DATE'),\n",
       " ('al', 'I-DATE'),\n",
       " ('ie', 'I-DATE'),\n",
       " ('ĠSy', 'I-DATE'),\n",
       " ('lla', 'B-MIDDLENAME'),\n",
       " ('Ġ', 'B-MIDDLENAME'),\n",
       " ('ĊĊ', 'B-LASTNAME'),\n",
       " ('ĠChallenge', 'O'),\n",
       " ('Ġ&', 'O'),\n",
       " ('Ġselection', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('ĊĊ', 'O'),\n",
       " ('ĠThe', 'O'),\n",
       " ('Ġtool', 'O'),\n",
       " ('ĠI', 'O'),\n",
       " ('Ġuse', 'O'),\n",
       " ('Ġto', 'O'),\n",
       " ('Ġhelp', 'O'),\n",
       " ('Ġall', 'O'),\n",
       " ('Ġstakeholders', 'O'),\n",
       " ('Ġfinding', 'O'),\n",
       " ('Ġtheir', 'O'),\n",
       " ('Ġway', 'O'),\n",
       " ('Ġthrough', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġcomplexity', 'O'),\n",
       " ('Ġof', 'O'),\n",
       " ('Ġa', 'O'),\n",
       " ('Ġproject', 'O'),\n",
       " ('Ġis', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġmap', 'O'),\n",
       " ('Ġ.', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('ĊĊ', 'O'),\n",
       " ('ĠWhat', 'O'),\n",
       " ('Ġexactly', 'O'),\n",
       " ('Ġis', 'O'),\n",
       " ('Ġa', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġmap', 'O'),\n",
       " ('Ġ?', 'O'),\n",
       " ('ĠAccording', 'O'),\n",
       " ('Ġto', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġdefinition', 'O'),\n",
       " ('Ġof', 'O'),\n",
       " ('ĠBu', 'O'),\n",
       " ('zan', 'O'),\n",
       " ('ĠT', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Ġand', 'O'),\n",
       " ('ĠBu', 'O'),\n",
       " ('zan', 'O'),\n",
       " ('ĠB', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Ġ(', 'O'),\n",
       " ('Ġ1999', 'O'),\n",
       " ('Ġ,', 'O'),\n",
       " ('ĠD', 'O'),\n",
       " ('ess', 'O'),\n",
       " ('ine', 'B-COMPANY_NAME'),\n",
       " ('Ġ-', 'B-COMPANY_NAME'),\n",
       " ('Ġmo', 'B-COMPANY_NAME'),\n",
       " ('i', 'I-COMPANY_NAME'),\n",
       " ('Ġ', 'I-COMPANY_NAME'),\n",
       " ('Ġl', 'I-COMPANY_NAME'),\n",
       " (\"'\", 'I-COMPANY_NAME'),\n",
       " ('intelligence', 'I-COMPANY_NAME'),\n",
       " ('Ġ.', 'I-COMPANY_NAME'),\n",
       " ('ĠParis', 'I-COMPANY_NAME'),\n",
       " ('Ġ:', 'O'),\n",
       " ('ĠLes', 'O'),\n",
       " ('ĠÃī', 'O'),\n",
       " ('d', 'O'),\n",
       " ('itions', 'O'),\n",
       " ('Ġd', 'O'),\n",
       " (\"'\", 'O'),\n",
       " ('Organ', 'O'),\n",
       " ('isation', 'O'),\n",
       " ('Ġ.', 'O'),\n",
       " ('Ġ)', 'O'),\n",
       " ('Ġ,', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġmap', 'O'),\n",
       " ('Ġ(', 'O'),\n",
       " ('Ġor', 'O'),\n",
       " ('Ġhe', 'O'),\n",
       " ('uristic', 'O'),\n",
       " ('Ġdiagram', 'O'),\n",
       " ('Ġ)', 'O'),\n",
       " ('Ġis', 'O'),\n",
       " ('Ġa', 'O'),\n",
       " ('Ġgraphic', 'O'),\n",
       " ('Ġ', 'O'),\n",
       " ('Ġrepresentation', 'O'),\n",
       " ('Ġtechnique', 'O'),\n",
       " ('Ġthat', 'O'),\n",
       " ('Ġfollows', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġnatural', 'O'),\n",
       " ('Ġfunctioning', 'O'),\n",
       " ('Ġof', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġmind', 'O'),\n",
       " ('Ġand', 'O'),\n",
       " ('Ġallows', 'O'),\n",
       " ('Ġthe', 'O'),\n",
       " ('Ġbrain', 'O'),\n",
       " ('[SEP]', 'O')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_labels = list(zip(list_tokens, pred_labels))\n",
    "token_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cffe98f0-edd1-4acd-81f8-336762c742fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x28a1e581800>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "833feb83-1689-4dbe-8ab6-8a19f5622cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Design', 'O'),\n",
       " ('Thinking', 'O'),\n",
       " ('for', 'O'),\n",
       " ('innovation', 'O'),\n",
       " ('reflexion', 'B-FIRSTNAME'),\n",
       " ('-', 'O'),\n",
       " ('Avril', 'I-FIRSTNAME'),\n",
       " ('2021', 'B-NUMBER'),\n",
       " ('-', 'I-NUMBER'),\n",
       " ('Nathalie', 'I-NUMBER'),\n",
       " ('Sylla', 'I-NUMBER'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('Challenge', 'O'),\n",
       " ('&', 'O'),\n",
       " ('selection', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('The', 'O'),\n",
       " ('tool', 'O'),\n",
       " ('I', 'O'),\n",
       " ('use', 'O'),\n",
       " ('to', 'O'),\n",
       " ('help', 'O'),\n",
       " ('all', 'O'),\n",
       " ('stakeholders', 'O'),\n",
       " ('finding', 'O'),\n",
       " ('their', 'O'),\n",
       " ('way', 'O'),\n",
       " ('through', 'O'),\n",
       " ('the', 'O'),\n",
       " ('complexity', 'O'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('project', 'O'),\n",
       " ('is', 'O'),\n",
       " ('the', 'O'),\n",
       " (' ', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('What', 'O'),\n",
       " ('exactly', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('?', 'O'),\n",
       " ('According', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('definition', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Buzan', 'O'),\n",
       " ('T.', 'O'),\n",
       " ('and', 'O'),\n",
       " ('Buzan', 'O'),\n",
       " ('B.', 'O'),\n",
       " ('(', 'O'),\n",
       " ('1999', 'O'),\n",
       " (',', 'O'),\n",
       " ('Dessine', 'B-COMPANY_NAME'),\n",
       " ('-', 'I-COMPANY_NAME'),\n",
       " ('moi', 'I-COMPANY_NAME'),\n",
       " (' ', 'I-COMPANY_NAME'),\n",
       " (\"l'intelligence\", 'I-COMPANY_NAME'),\n",
       " ('.', 'O'),\n",
       " ('Paris', 'O'),\n",
       " (':', 'O'),\n",
       " ('Les', 'O'),\n",
       " ('Éditions', 'O'),\n",
       " (\"d'Organisation\", 'O'),\n",
       " ('.', 'O'),\n",
       " (')', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('(', 'O'),\n",
       " ('or', 'O'),\n",
       " ('heuristic', 'O'),\n",
       " ('diagram', 'O'),\n",
       " (')', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('graphic', 'O'),\n",
       " (' ', 'O'),\n",
       " ('representation', 'O'),\n",
       " ('technique', 'O'),\n",
       " ('that', 'O'),\n",
       " ('follows', 'O'),\n",
       " ('the', 'O'),\n",
       " ('natural', 'O'),\n",
       " ('functioning', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('and', 'O'),\n",
       " ('allows', 'O'),\n",
       " ('the', 'O'),\n",
       " ('brain', 'O')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1c2615e-3513-4a6f-a0ba-b45638e5a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Design',\n",
       " 'Thinking',\n",
       " 'for',\n",
       " 'innovation',\n",
       " 'reflexion',\n",
       " '-',\n",
       " 'Avril',\n",
       " '2021',\n",
       " '-',\n",
       " 'Nathalie',\n",
       " 'Sylla',\n",
       " '\\n\\n',\n",
       " 'Challenge',\n",
       " '&',\n",
       " 'selection',\n",
       " '\\n\\n',\n",
       " 'The',\n",
       " 'tool',\n",
       " 'I',\n",
       " 'use']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07ae571f-918e-44a8-9127-475e5867e3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'ĠDesign',\n",
       " 'ĠThinking',\n",
       " 'Ġfor',\n",
       " 'Ġinnovation',\n",
       " 'Ġreflex',\n",
       " 'ion',\n",
       " 'Ġ-',\n",
       " 'ĠAv',\n",
       " 'ril',\n",
       " 'Ġ2021',\n",
       " 'Ġ-',\n",
       " 'ĠNath',\n",
       " 'al',\n",
       " 'ie',\n",
       " 'ĠSy',\n",
       " 'lla',\n",
       " 'Ġ',\n",
       " 'ĊĊ',\n",
       " 'ĠChallenge']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68827dde-695c-4841-9597-6c8aaf327a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reflexion'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_v[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc645684-58d7-4bc9-9ae6-05e380520ba6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1],\n",
       " 1: [2],\n",
       " 2: [3],\n",
       " 3: [4],\n",
       " 4: [5, 6],\n",
       " 5: [7],\n",
       " 6: [8, 9],\n",
       " 7: [10],\n",
       " 8: [11],\n",
       " 9: [12, 13, 14],\n",
       " 10: [15, 16],\n",
       " 11: [17, 18],\n",
       " 12: [19],\n",
       " 13: [20],\n",
       " 14: [21],\n",
       " 15: [22, 23],\n",
       " 16: [24],\n",
       " 17: [25],\n",
       " 18: [26],\n",
       " 19: [27],\n",
       " 20: [28],\n",
       " 21: [29],\n",
       " 22: [30],\n",
       " 23: [31],\n",
       " 24: [32],\n",
       " 25: [33],\n",
       " 26: [34],\n",
       " 27: [35],\n",
       " 28: [36],\n",
       " 29: [37],\n",
       " 30: [38],\n",
       " 31: [39],\n",
       " 32: [40],\n",
       " 33: [41],\n",
       " 34: [42],\n",
       " 35: [43],\n",
       " 36: [44],\n",
       " 37: [45],\n",
       " 38: [46],\n",
       " 39: [47, 48],\n",
       " 40: [49],\n",
       " 41: [50],\n",
       " 42: [51],\n",
       " 43: [52],\n",
       " 44: [53],\n",
       " 45: [54],\n",
       " 46: [55],\n",
       " 47: [56],\n",
       " 48: [57],\n",
       " 49: [58],\n",
       " 50: [59],\n",
       " 51: [60],\n",
       " 52: [61, 62],\n",
       " 53: [63, 64],\n",
       " 54: [65],\n",
       " 55: [66, 67],\n",
       " 56: [68, 69],\n",
       " 57: [70],\n",
       " 58: [71],\n",
       " 59: [72],\n",
       " 60: [73, 74, 75],\n",
       " 61: [76],\n",
       " 62: [77, 78],\n",
       " 63: [79],\n",
       " 64: [80, 81, 82],\n",
       " 65: [83],\n",
       " 66: [84],\n",
       " 67: [85],\n",
       " 68: [86],\n",
       " 69: [87, 88, 89],\n",
       " 70: [90, 91, 92, 93],\n",
       " 71: [94],\n",
       " 72: [95],\n",
       " 73: [96],\n",
       " 74: [97],\n",
       " 75: [98],\n",
       " 76: [99],\n",
       " 77: [100],\n",
       " 78: [101],\n",
       " 79: [102, 103],\n",
       " 80: [104],\n",
       " 81: [105],\n",
       " 82: [106],\n",
       " 83: [107],\n",
       " 84: [108],\n",
       " 85: [109],\n",
       " 86: [110],\n",
       " 87: [111],\n",
       " 88: [112],\n",
       " 89: [113],\n",
       " 90: [114],\n",
       " 91: [115],\n",
       " 92: [116],\n",
       " 93: [117],\n",
       " 94: [118],\n",
       " 95: [119],\n",
       " 96: [120],\n",
       " 97: [121],\n",
       " 98: [122],\n",
       " 99: [123]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_subword_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3d15253-e1d0-49b3-a503-21cbe0d5968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_v, pred_v = zip(*word_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8ae2cbe-38de-47ff-ac60-af23611eaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = [token.text_with_ws for token in doc[:100]]\n",
    "list_tokens = inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62b1afeb-27c2-4533-bfb3-f85c7f6f357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens back to words\n",
    "text_recon = tokenizer.convert_tokens_to_string(list_tokens)\n",
    "\n",
    "# Split the sentence into a list of words\n",
    "list_words_2 = text_recon.split()\n",
    "list_words_2_adj = list_words_2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85d53250-0b35-4d69-b90a-36e4edcb6955",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Design',\n",
       " 'Thinking',\n",
       " 'for',\n",
       " 'innovation',\n",
       " 'reflexion-Avril',\n",
       " '2021-Nathalie',\n",
       " 'Sylla',\n",
       " 'Challenge',\n",
       " '&',\n",
       " 'selection',\n",
       " 'The',\n",
       " 'tool',\n",
       " 'I',\n",
       " 'use',\n",
       " 'to',\n",
       " 'help',\n",
       " 'all',\n",
       " 'stakeholders',\n",
       " 'finding',\n",
       " 'their',\n",
       " 'way',\n",
       " 'through',\n",
       " 'the',\n",
       " 'complexity',\n",
       " 'of',\n",
       " 'a',\n",
       " 'project',\n",
       " 'is',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map.',\n",
       " 'What',\n",
       " 'exactly',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mind',\n",
       " 'map?',\n",
       " 'According',\n",
       " 'to',\n",
       " 'the',\n",
       " 'definition',\n",
       " 'of',\n",
       " 'Buzan',\n",
       " 'T.',\n",
       " 'and',\n",
       " 'Buzan',\n",
       " 'B.',\n",
       " '(1999,',\n",
       " 'Dessine-moi',\n",
       " \"l'intelligence.\",\n",
       " 'Paris:',\n",
       " 'Les',\n",
       " 'Éditions',\n",
       " \"d'Organisation.),\",\n",
       " 'the',\n",
       " 'mind',\n",
       " 'map',\n",
       " '(or',\n",
       " 'heuristic',\n",
       " 'diagram)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'graphic',\n",
       " 'representation',\n",
       " 'technique',\n",
       " 'that',\n",
       " 'follows',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'functioning',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'and',\n",
       " 'allows',\n",
       " 'the',\n",
       " 'brain[SEP]']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f97acfe0-1673-4472-a955-5ad1ce7cd9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Design  ===> ['ĠDesign']\n",
      "1 : Thinking  ===> ['ĠThinking']\n",
      "2 : for  ===> ['Ġfor']\n",
      "3 : innovation  ===> ['Ġinnovation']\n",
      "4 : reflexion ===> ['Ġreflex', 'ion']\n",
      "5 : - ===> ['Ġ-']\n",
      "6 : Avril  ===> ['ĠAv', 'ril']\n",
      "7 : 2021 ===> ['Ġ2021']\n",
      "8 : - ===> ['Ġ-']\n",
      "9 : Nathalie  ===> ['ĠNath', 'al', 'ie']\n",
      "10 : Sylla ===> ['ĠSy', 'lla']\n",
      "11 : \n",
      "\n",
      " ===> ['Ġ', 'ĊĊ']\n",
      "12 : Challenge  ===> ['ĠChallenge']\n",
      "13 : &  ===> ['Ġ&']\n",
      "14 : selection ===> ['Ġselection']\n",
      "15 : \n",
      "\n",
      " ===> ['Ġ', 'ĊĊ']\n",
      "16 : The  ===> ['ĠThe']\n",
      "17 : tool  ===> ['Ġtool']\n",
      "18 : I  ===> ['ĠI']\n",
      "19 : use  ===> ['Ġuse']\n",
      "20 : to  ===> ['Ġto']\n",
      "21 : help  ===> ['Ġhelp']\n",
      "22 : all  ===> ['Ġall']\n",
      "23 : stakeholders  ===> ['Ġstakeholders']\n",
      "24 : finding  ===> ['Ġfinding']\n",
      "25 : their  ===> ['Ġtheir']\n",
      "26 : way  ===> ['Ġway']\n",
      "27 : through  ===> ['Ġthrough']\n",
      "28 : the  ===> ['Ġthe']\n",
      "29 : complexity  ===> ['Ġcomplexity']\n",
      "30 : of  ===> ['Ġof']\n",
      "31 : a  ===> ['Ġa']\n",
      "32 : project  ===> ['Ġproject']\n",
      "33 : is  ===> ['Ġis']\n",
      "34 : the  ===> ['Ġthe']\n",
      "35 :   ===> ['Ġ']\n",
      "36 : mind  ===> ['Ġmind']\n",
      "37 : map ===> ['Ġmap']\n",
      "38 : . ===> ['Ġ.']\n",
      "39 : \n",
      "\n",
      " ===> ['Ġ', 'ĊĊ']\n",
      "40 : What  ===> ['ĠWhat']\n",
      "41 : exactly  ===> ['Ġexactly']\n",
      "42 : is  ===> ['Ġis']\n",
      "43 : a  ===> ['Ġa']\n",
      "44 : mind  ===> ['Ġmind']\n",
      "45 : map ===> ['Ġmap']\n",
      "46 : ?  ===> ['Ġ?']\n",
      "47 : According  ===> ['ĠAccording']\n",
      "48 : to  ===> ['Ġto']\n",
      "49 : the  ===> ['Ġthe']\n",
      "50 : definition  ===> ['Ġdefinition']\n",
      "51 : of  ===> ['Ġof']\n",
      "52 : Buzan  ===> ['ĠBu', 'zan']\n",
      "53 : T.  ===> ['ĠT', '.']\n",
      "54 : and  ===> ['Ġand']\n",
      "55 : Buzan  ===> ['ĠBu', 'zan']\n",
      "56 : B.  ===> ['ĠB', '.']\n",
      "57 : ( ===> ['Ġ(']\n",
      "58 : 1999 ===> ['Ġ1999']\n",
      "59 : ,  ===> ['Ġ,']\n",
      "60 : Dessine ===> ['ĠD', 'ess', 'ine']\n",
      "61 : - ===> ['Ġ-']\n",
      "62 : moi  ===> ['Ġmo', 'i']\n",
      "63 :   ===> ['Ġ']\n",
      "64 : l'intelligence ===> ['Ġl', \"'\", 'intelligence']\n",
      "65 : .  ===> ['Ġ.']\n",
      "66 : Paris ===> ['ĠParis']\n",
      "67 : :  ===> ['Ġ:']\n",
      "68 : Les  ===> ['ĠLes']\n",
      "69 : Éditions  ===> ['ĠÃī', 'd', 'itions']\n",
      "70 : d'Organisation ===> ['Ġd', \"'\", 'Organ', 'isation']\n",
      "71 : . ===> ['Ġ.']\n",
      "72 : ) ===> ['Ġ)']\n",
      "73 : ,  ===> ['Ġ,']\n",
      "74 : the  ===> ['Ġthe']\n",
      "75 : mind  ===> ['Ġmind']\n",
      "76 : map  ===> ['Ġmap']\n",
      "77 : ( ===> ['Ġ(']\n",
      "78 : or  ===> ['Ġor']\n",
      "79 : heuristic  ===> ['Ġhe', 'uristic']\n",
      "80 : diagram ===> ['Ġdiagram']\n",
      "81 : )  ===> ['Ġ)']\n",
      "82 : is  ===> ['Ġis']\n",
      "83 : a  ===> ['Ġa']\n",
      "84 : graphic  ===> ['Ġgraphic']\n",
      "85 :   ===> ['Ġ']\n",
      "86 : representation  ===> ['Ġrepresentation']\n",
      "87 : technique  ===> ['Ġtechnique']\n",
      "88 : that  ===> ['Ġthat']\n",
      "89 : follows  ===> ['Ġfollows']\n",
      "90 : the  ===> ['Ġthe']\n",
      "91 : natural  ===> ['Ġnatural']\n",
      "92 : functioning  ===> ['Ġfunctioning']\n",
      "93 : of  ===> ['Ġof']\n",
      "94 : the  ===> ['Ġthe']\n",
      "95 : mind  ===> ['Ġmind']\n",
      "96 : and  ===> ['Ġand']\n",
      "97 : allows  ===> ['Ġallows']\n",
      "98 : the  ===> ['Ġthe']\n",
      "99 : brain ===> ['Ġbrain']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(word_subword_mapping)):\n",
    "    list_j = word_subword_mapping[i]\n",
    "    subwords = [list_tokens[j] for j in list_j]\n",
    "    print(f'{i} : {list_words[i]} ===> {subwords}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "799125e1-d369-4f1b-9e07-eb9fcf795d88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_words_2_adj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m list_j \u001b[38;5;241m=\u001b[39m word_subword_mapping[i]\n\u001b[0;32m      3\u001b[0m subwords \u001b[38;5;241m=\u001b[39m [list_tokens[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m list_j]\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlist_words_2_adj\u001b[49m[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubwords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list_words_2_adj' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(word_subword_mapping)):\n",
    "    list_j = word_subword_mapping[i]\n",
    "    subwords = [list_tokens[j] for j in list_j]\n",
    "    print(f'{i} : {list_words_2_adj[i]} ===> {subwords}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f18d1-c1e9-4f35-b1a4-d739b14632fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a770d8c-90df-4827-b9b5-31de910d5dab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1],\n",
       " 1: [2],\n",
       " 2: [3],\n",
       " 3: [4],\n",
       " 4: [5, 6],\n",
       " 5: [7],\n",
       " 6: [8, 9],\n",
       " 7: [10],\n",
       " 8: [11],\n",
       " 9: [12, 13, 14, 15],\n",
       " 10: [16, 17],\n",
       " 11: [18],\n",
       " 12: [19],\n",
       " 13: [20, 21],\n",
       " 14: [22],\n",
       " 15: [23],\n",
       " 16: [24],\n",
       " 17: [25],\n",
       " 18: [26],\n",
       " 19: [27],\n",
       " 20: [28],\n",
       " 21: [29],\n",
       " 22: [30],\n",
       " 23: [31],\n",
       " 24: [32],\n",
       " 25: [33],\n",
       " 26: [34],\n",
       " 27: [35],\n",
       " 28: [36],\n",
       " 29: [37],\n",
       " 30: [38],\n",
       " 31: [39],\n",
       " 32: [40],\n",
       " 33: [41],\n",
       " 34: [42],\n",
       " 35: [43],\n",
       " 36: [44],\n",
       " 37: [45],\n",
       " 38: [46],\n",
       " 39: [47],\n",
       " 40: [48],\n",
       " 41: [49],\n",
       " 42: [50],\n",
       " 43: [51],\n",
       " 44: [52],\n",
       " 45: [53],\n",
       " 46: [54],\n",
       " 47: [55],\n",
       " 48: [56],\n",
       " 49: [57],\n",
       " 50: [58],\n",
       " 51: [59],\n",
       " 52: [60],\n",
       " 53: [61],\n",
       " 54: [62],\n",
       " 55: [63, 64],\n",
       " 56: [65],\n",
       " 57: [66],\n",
       " 58: [67],\n",
       " 59: [68, 69],\n",
       " 60: [70],\n",
       " 61: [71],\n",
       " 62: [72],\n",
       " 63: [73],\n",
       " 64: [74],\n",
       " 65: [75, 76, 77],\n",
       " 66: [78],\n",
       " 67: [79, 80],\n",
       " 68: [81],\n",
       " 69: [82],\n",
       " 70: [83],\n",
       " 71: [84],\n",
       " 72: [85],\n",
       " 73: [86],\n",
       " 74: [87],\n",
       " 75: [88],\n",
       " 76: [89, 90, 91],\n",
       " 77: [92],\n",
       " 78: [93],\n",
       " 79: [94, 95],\n",
       " 80: [96],\n",
       " 81: [97],\n",
       " 82: [98],\n",
       " 83: [99],\n",
       " 84: [100],\n",
       " 85: [101],\n",
       " 86: [102, 103],\n",
       " 87: [104],\n",
       " 88: [105],\n",
       " 89: [106],\n",
       " 90: [107],\n",
       " 91: [108],\n",
       " 92: [109],\n",
       " 93: [110],\n",
       " 94: [111],\n",
       " 95: [112],\n",
       " 96: [113],\n",
       " 97: [114],\n",
       " 98: [115],\n",
       " 99: [116],\n",
       " 100: [117],\n",
       " 101: [118],\n",
       " 102: [119],\n",
       " 103: [120],\n",
       " 104: [121],\n",
       " 105: [122],\n",
       " 106: [123]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_subword_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf6f9e-3c81-4951-a291-af5eb8b54bba",
   "metadata": {},
   "source": [
    "### To Do: Check word-subword mappings -> indices to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ceec35f7-8c9e-419c-a54d-2b94e664657b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Design', 'O'),\n",
       " ('Thinking', 'O'),\n",
       " ('for', 'O'),\n",
       " ('innovation', 'O'),\n",
       " ('reflexion', 'O'),\n",
       " ('-', 'O'),\n",
       " ('Avril', 'O'),\n",
       " ('2021', 'B-DATE'),\n",
       " ('-', 'I-DATE'),\n",
       " ('Nathalie', 'I-DATE'),\n",
       " ('Sylla', 'B-MIDDLENAME'),\n",
       " ('\\n\\n', 'B-LASTNAME'),\n",
       " ('Challenge', 'O'),\n",
       " ('&', 'O'),\n",
       " ('selection', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('The', 'O'),\n",
       " ('tool', 'O'),\n",
       " ('I', 'O'),\n",
       " ('use', 'O'),\n",
       " ('to', 'O'),\n",
       " ('help', 'O'),\n",
       " ('all', 'O'),\n",
       " ('stakeholders', 'O'),\n",
       " ('finding', 'O'),\n",
       " ('their', 'O'),\n",
       " ('way', 'O'),\n",
       " ('through', 'O'),\n",
       " ('the', 'O'),\n",
       " ('complexity', 'O'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('project', 'O'),\n",
       " ('is', 'O'),\n",
       " ('the', 'O'),\n",
       " (' ', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('What', 'O'),\n",
       " ('exactly', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('?', 'O'),\n",
       " ('According', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('definition', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Buzan', 'O'),\n",
       " ('T.', 'O'),\n",
       " ('and', 'O'),\n",
       " ('Buzan', 'B-MIDDLENAME'),\n",
       " ('B.', 'O'),\n",
       " ('(', 'O'),\n",
       " ('1999', 'O'),\n",
       " (',', 'O'),\n",
       " ('Dessine', 'O'),\n",
       " ('-', 'O'),\n",
       " ('moi', 'O'),\n",
       " (' ', 'O'),\n",
       " (\"l'intelligence\", 'O'),\n",
       " ('.', 'B-COMPANY_NAME'),\n",
       " ('Paris', 'I-COMPANY_NAME'),\n",
       " (':', 'I-COMPANY_NAME'),\n",
       " ('Les', 'I-COMPANY_NAME'),\n",
       " ('Éditions', 'I-COMPANY_NAME'),\n",
       " (\"d'Organisation\", 'I-COMPANY_NAME'),\n",
       " ('.', 'I-COMPANY_NAME'),\n",
       " (')', 'O'),\n",
       " (',', 'O'),\n",
       " ('the', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('(', 'O'),\n",
       " ('or', 'O'),\n",
       " ('heuristic', 'O'),\n",
       " ('diagram', 'O'),\n",
       " (')', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('graphic', 'O'),\n",
       " (' ', 'O'),\n",
       " ('representation', 'O'),\n",
       " ('technique', 'O'),\n",
       " ('that', 'O'),\n",
       " ('follows', 'O'),\n",
       " ('the', 'O'),\n",
       " ('natural', 'O'),\n",
       " ('functioning', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('and', 'O'),\n",
       " ('allows', 'O'),\n",
       " ('the', 'O'),\n",
       " ('brain', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " (' ', 'O'),\n",
       " ('potential', 'O'),\n",
       " ('to', 'O'),\n",
       " ('be', 'O'),\n",
       " ('released', 'O'),\n",
       " ('.', 'O'),\n",
       " ('Cf', 'O'),\n",
       " ('Annex1', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('This', 'O'),\n",
       " ('tool', 'O'),\n",
       " ('has', 'O'),\n",
       " ('many', 'O'),\n",
       " ('advantages', 'O'),\n",
       " (':', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('is', 'O'),\n",
       " ('accessible', 'O'),\n",
       " ('to', 'O'),\n",
       " ('all', 'O'),\n",
       " ('and', 'O'),\n",
       " ('does', 'O'),\n",
       " ('not', 'O'),\n",
       " ('require', 'O'),\n",
       " ('significant', 'O'),\n",
       " ('material', 'O'),\n",
       " ('investment', 'O'),\n",
       " ('and', 'O'),\n",
       " ('can', 'O'),\n",
       " ('be', 'O'),\n",
       " ('done', 'O'),\n",
       " (' ', 'O'),\n",
       " ('quickly', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('is', 'O'),\n",
       " ('scalable', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('allows', 'O'),\n",
       " ('categorization', 'O'),\n",
       " ('and', 'O'),\n",
       " ('linking', 'O'),\n",
       " ('of', 'O'),\n",
       " ('information', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('can', 'O'),\n",
       " ('be', 'O'),\n",
       " ('applied', 'O'),\n",
       " ('to', 'O'),\n",
       " ('any', 'O'),\n",
       " ('type', 'O'),\n",
       " ('of', 'O'),\n",
       " ('situation', 'O'),\n",
       " (':', 'O'),\n",
       " ('notetaking', 'O'),\n",
       " (',', 'O'),\n",
       " ('problem', 'O'),\n",
       " ('solving', 'O'),\n",
       " (',', 'O'),\n",
       " ('analysis', 'O'),\n",
       " (',', 'O'),\n",
       " ('creation', 'O'),\n",
       " ('of', 'O'),\n",
       " (' ', 'O'),\n",
       " ('new', 'O'),\n",
       " ('ideas', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('is', 'O'),\n",
       " ('suitable', 'O'),\n",
       " ('for', 'O'),\n",
       " ('all', 'O'),\n",
       " ('people', 'O'),\n",
       " ('and', 'O'),\n",
       " ('is', 'O'),\n",
       " ('easy', 'O'),\n",
       " ('to', 'O'),\n",
       " ('learn', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('is', 'O'),\n",
       " ('fun', 'O'),\n",
       " ('and', 'O'),\n",
       " ('encourages', 'O'),\n",
       " ('exchanges', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('makes', 'O'),\n",
       " ('visible', 'O'),\n",
       " ('the', 'O'),\n",
       " ('dimension', 'O'),\n",
       " ('of', 'O'),\n",
       " ('projects', 'O'),\n",
       " (',', 'O'),\n",
       " ('opportunities', 'O'),\n",
       " (',', 'O'),\n",
       " ('interconnections', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('synthesizes', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('makes', 'O'),\n",
       " ('the', 'O'),\n",
       " ('project', 'O'),\n",
       " ('understandable', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('•', 'O'),\n",
       " (' ', 'O'),\n",
       " ('It', 'O'),\n",
       " ('allows', 'O'),\n",
       " ('you', 'O'),\n",
       " ('to', 'O'),\n",
       " ('explore', 'O'),\n",
       " ('ideas', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('The', 'O'),\n",
       " ('creation', 'O'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('starts', 'O'),\n",
       " ('with', 'O'),\n",
       " ('an', 'O'),\n",
       " ('idea', 'O'),\n",
       " ('/', 'O'),\n",
       " ('problem', 'O'),\n",
       " ('located', 'O'),\n",
       " ('at', 'O'),\n",
       " ('its', 'O'),\n",
       " ('center', 'O'),\n",
       " ('.', 'O'),\n",
       " ('This', 'O'),\n",
       " ('starting', 'O'),\n",
       " ('point', 'O'),\n",
       " (' ', 'O'),\n",
       " ('generates', 'O'),\n",
       " ('ideas', 'O'),\n",
       " ('/', 'O'),\n",
       " ('work', 'O'),\n",
       " ('areas', 'O'),\n",
       " (',', 'O'),\n",
       " ('incremented', 'O'),\n",
       " ('around', 'O'),\n",
       " ('this', 'O'),\n",
       " ('center', 'O'),\n",
       " ('in', 'O'),\n",
       " ('a', 'O'),\n",
       " ('radial', 'O'),\n",
       " ('structure', 'O'),\n",
       " (',', 'O'),\n",
       " ('which', 'O'),\n",
       " ('in', 'O'),\n",
       " ('turn', 'O'),\n",
       " ('is', 'O'),\n",
       " (' ', 'O'),\n",
       " ('completed', 'O'),\n",
       " ('with', 'O'),\n",
       " ('as', 'O'),\n",
       " ('many', 'O'),\n",
       " ('branches', 'O'),\n",
       " ('as', 'O'),\n",
       " ('new', 'O'),\n",
       " ('ideas', 'O'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('This', 'O'),\n",
       " ('tool', 'O'),\n",
       " ('enables', 'O'),\n",
       " ('creativity', 'O'),\n",
       " ('and', 'O'),\n",
       " ('logic', 'O'),\n",
       " ('to', 'O'),\n",
       " ('be', 'O'),\n",
       " ('mobilized', 'O'),\n",
       " (',', 'O'),\n",
       " ('it', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('map', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('thoughts', 'O'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('Creativity', 'O'),\n",
       " ('is', 'O'),\n",
       " ('enhanced', 'O'),\n",
       " ('because', 'O'),\n",
       " ('participants', 'O'),\n",
       " ('feel', 'O'),\n",
       " ('comfortable', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('method', 'O'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('Application', 'O'),\n",
       " ('&', 'O'),\n",
       " ('Insight', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('I', 'O'),\n",
       " ('start', 'O'),\n",
       " ('the', 'O'),\n",
       " ('process', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('mind', 'O'),\n",
       " ('map', 'O'),\n",
       " ('creation', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('stakeholders', 'O'),\n",
       " ('standing', 'O'),\n",
       " ('around', 'O'),\n",
       " ('a', 'O'),\n",
       " ('large', 'O'),\n",
       " ('board', 'O'),\n",
       " (' ', 'O'),\n",
       " ('(', 'O'),\n",
       " ('white', 'O'),\n",
       " ('or', 'O'),\n",
       " ('paper', 'O'),\n",
       " ('board', 'O'),\n",
       " (')', 'O'),\n",
       " ('.', 'O'),\n",
       " ('In', 'O')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69f0eb-564b-4cb9-a6fd-1d8807530dc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reconstruct (Visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba69db3-18b3-4d68-b31c-c506c1126376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_span(record):\n",
    "    \n",
    "    global span_infos\n",
    "    \n",
    "    start_pos = -1\n",
    "    span_infos = []\n",
    "    for label_index, label in enumerate(record['labels']):\n",
    "        if re.match('^B-', label):\n",
    "            start_pos = label_index\n",
    "            label_group = label.split('-')[1]\n",
    "\n",
    "        if re.match('O', label) and start_pos != -1:\n",
    "            end_pos = label_index\n",
    "            span_dict = {'start_pos':start_pos, 'end_pos':end_pos, 'label_group':label_group}\n",
    "            span_infos.append(span_dict)\n",
    "            start_pos = -1\n",
    "\n",
    "    doc_spans = []\n",
    "    nlp = spacy.blank('en')\n",
    "    doc = nlp(record['full_text'])\n",
    "    for span_info in span_infos:\n",
    "        _span = Span(doc, span_info['start_pos'], span_info['end_pos'], span_info['label_group'])\n",
    "        doc_spans.append(_span)\n",
    "\n",
    "    doc.spans['sc'] = doc_spans\n",
    "\n",
    "    displacy.render(doc, style = 'span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9032f2cf-7f6f-4b1b-bced-2c1ca9405586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_span(full_text, tokens, labels):\n",
    "    \n",
    "    global span_infos\n",
    "    \n",
    "    start_pos = -1\n",
    "    span_infos = []\n",
    "    for label_index, label in enumerate(labels):\n",
    "        if re.match('^B-', label):\n",
    "            start_pos = label_index\n",
    "            label_group = label.split('-')[1]\n",
    "\n",
    "        if re.match('O', label) and start_pos != -1:\n",
    "            end_pos = label_index\n",
    "            span_dict = {'start_pos':start_pos, 'end_pos':end_pos, 'label_group':label_group}\n",
    "            span_infos.append(span_dict)\n",
    "            start_pos = -1\n",
    "\n",
    "    doc_spans = []\n",
    "    nlp = spacy.blank('en')\n",
    "    doc = nlp(full_text)\n",
    "    for span_info in span_infos:\n",
    "        _span = Span(doc, span_info['start_pos'], span_info['end_pos'], span_info['label_group'])\n",
    "        doc_spans.append(_span)\n",
    "\n",
    "    doc.spans['sc'] = doc_spans\n",
    "\n",
    "    displacy.render(doc, style = 'span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d4a1d-242a-4f8c-9931-9f66149f8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(*word_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8caa471e-2fbd-4d1b-a174-075b04a1c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nChallenge & selection\\n\\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\\n\\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c062b479-5102-48c0-a654-eb61e1b3e429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Design',\n",
       " 'Thinking',\n",
       " 'for',\n",
       " 'innovation',\n",
       " 'reflexion',\n",
       " '-',\n",
       " 'Avril',\n",
       " '2021',\n",
       " '-',\n",
       " 'Nathalie',\n",
       " 'Sylla',\n",
       " '\\n\\n',\n",
       " 'Challenge',\n",
       " '&',\n",
       " 'selection')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_v[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5372c319-74e3-4de0-9daf-d8b79a527fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FIRSTNAME',\n",
       " 'O',\n",
       " 'I-FIRSTNAME',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_v[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f41e5d59-5044-4ec5-8e15-e0b143cddf69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1],\n",
       " 1: [2],\n",
       " 2: [3],\n",
       " 3: [4],\n",
       " 4: [5, 6],\n",
       " 5: [7],\n",
       " 6: [8, 9],\n",
       " 7: [10],\n",
       " 8: [11],\n",
       " 9: [12, 13, 14, 15],\n",
       " 10: [16, 17],\n",
       " 11: [18],\n",
       " 12: [19],\n",
       " 13: [20, 21],\n",
       " 14: [22],\n",
       " 15: [23],\n",
       " 16: [24],\n",
       " 17: [25],\n",
       " 18: [26],\n",
       " 19: [27],\n",
       " 20: [28],\n",
       " 21: [29],\n",
       " 22: [30],\n",
       " 23: [31],\n",
       " 24: [32],\n",
       " 25: [33],\n",
       " 26: [34],\n",
       " 27: [35],\n",
       " 28: [36],\n",
       " 29: [37],\n",
       " 30: [38],\n",
       " 31: [39],\n",
       " 32: [40],\n",
       " 33: [41],\n",
       " 34: [42],\n",
       " 35: [43],\n",
       " 36: [44],\n",
       " 37: [45],\n",
       " 38: [46],\n",
       " 39: [47],\n",
       " 40: [48],\n",
       " 41: [49],\n",
       " 42: [50],\n",
       " 43: [51],\n",
       " 44: [52],\n",
       " 45: [53],\n",
       " 46: [54],\n",
       " 47: [55],\n",
       " 48: [56],\n",
       " 49: [57],\n",
       " 50: [58],\n",
       " 51: [59],\n",
       " 52: [60],\n",
       " 53: [61],\n",
       " 54: [62],\n",
       " 55: [63, 64],\n",
       " 56: [65],\n",
       " 57: [66],\n",
       " 58: [67],\n",
       " 59: [68, 69],\n",
       " 60: [70],\n",
       " 61: [71],\n",
       " 62: [72],\n",
       " 63: [73],\n",
       " 64: [74],\n",
       " 65: [75, 76, 77],\n",
       " 66: [78],\n",
       " 67: [79, 80],\n",
       " 68: [81],\n",
       " 69: [82],\n",
       " 70: [83],\n",
       " 71: [84],\n",
       " 72: [85],\n",
       " 73: [86],\n",
       " 74: [87],\n",
       " 75: [88],\n",
       " 76: [89, 90, 91],\n",
       " 77: [92],\n",
       " 78: [93],\n",
       " 79: [94, 95],\n",
       " 80: [96],\n",
       " 81: [97],\n",
       " 82: [98],\n",
       " 83: [99],\n",
       " 84: [100],\n",
       " 85: [101],\n",
       " 86: [102, 103],\n",
       " 87: [104],\n",
       " 88: [105],\n",
       " 89: [106],\n",
       " 90: [107],\n",
       " 91: [108],\n",
       " 92: [109],\n",
       " 93: [110],\n",
       " 94: [111],\n",
       " 95: [112],\n",
       " 96: [113],\n",
       " 97: [114],\n",
       " 98: [115],\n",
       " 99: [116],\n",
       " 100: [117],\n",
       " 101: [118],\n",
       " 102: [119],\n",
       " 103: [120],\n",
       " 104: [121],\n",
       " 105: [122],\n",
       " 106: [123]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_subword_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "59a1203e-9371-4257-af7b-f532a0807feb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Meet', 'O'),\n",
       " ('Jane', 'B-FIRSTNAME'),\n",
       " ('Doe', 'O'),\n",
       " (',', 'O'),\n",
       " ('a', 'O'),\n",
       " ('brilliant', 'O'),\n",
       " ('student', 'O'),\n",
       " ('at', 'O'),\n",
       " ('XYZ', 'O'),\n",
       " ('University', 'O'),\n",
       " ('.', 'O'),\n",
       " ('She', 'O'),\n",
       " ('can', 'O'),\n",
       " ('be', 'O'),\n",
       " ('reached', 'O'),\n",
       " ('at', 'O'),\n",
       " ('jane.doe@email.com', 'I-EMAIL'),\n",
       " ('or', 'O'),\n",
       " ('through', 'O'),\n",
       " ('her', 'O'),\n",
       " ('phone', 'O'),\n",
       " ('number', 'O'),\n",
       " ('+1234567890', 'I-PHONE_NUMBER'),\n",
       " ('.', 'O'),\n",
       " ('Jane', 'B-FIRSTNAME'),\n",
       " ('resides', 'O'),\n",
       " ('at', 'O'),\n",
       " ('123', 'B-STREETADDRESS'),\n",
       " ('Main', 'I-STREETADDRESS'),\n",
       " ('Street', 'I-STREETADDRESS'),\n",
       " (',', 'O'),\n",
       " ('Cityville', 'B-CITY'),\n",
       " ('.', 'O'),\n",
       " ('Her', 'O'),\n",
       " ('student', 'O'),\n",
       " ('ID', 'O'),\n",
       " ('is', 'O'),\n",
       " ('987654', 'B-ZIPCODE'),\n",
       " ('and', 'O'),\n",
       " ('her', 'O'),\n",
       " ('personal', 'O'),\n",
       " ('website', 'O'),\n",
       " ('is', 'O'),\n",
       " ('www.janedoe.com', 'I-URL'),\n",
       " ('.', 'O'),\n",
       " ('Connect', 'O'),\n",
       " ('with', 'O'),\n",
       " ('her', 'O'),\n",
       " ('on', 'O'),\n",
       " ('social', 'O'),\n",
       " ('media', 'O'),\n",
       " ('using', 'O'),\n",
       " ('the', 'O'),\n",
       " ('username', 'O'),\n",
       " ('@janedoe', 'B-MIDDLENAME'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('Meanwhile', 'O'),\n",
       " (',', 'O'),\n",
       " ('John', 'B-FIRSTNAME'),\n",
       " ('Smith', 'B-LASTNAME'),\n",
       " (',', 'O'),\n",
       " ('another', 'O'),\n",
       " ('outstanding', 'O'),\n",
       " ('student', 'O'),\n",
       " (',', 'O'),\n",
       " ('can', 'O'),\n",
       " ('be', 'O'),\n",
       " ('contacted', 'O'),\n",
       " ('at', 'O'),\n",
       " ('john.smith@email.com', 'I-EMAIL'),\n",
       " ('or', 'O'),\n",
       " ('at', 'O'),\n",
       " ('+9876543210', 'I-PHONE_NUMBER'),\n",
       " ('.', 'O'),\n",
       " ('John', 'O'),\n",
       " ('lives', 'O'),\n",
       " ('at', 'O'),\n",
       " ('456', 'B-STREETADDRESS'),\n",
       " ('Oak', 'I-STREETADDRESS'),\n",
       " ('Avenue', 'I-STREETADDRESS'),\n",
       " (',', 'O'),\n",
       " ('Townsville', 'B-CITY'),\n",
       " ('.', 'O'),\n",
       " ('His', 'O'),\n",
       " ('student', 'O'),\n",
       " ('ID', 'O'),\n",
       " ('is', 'O'),\n",
       " ('123456', 'B-ZIPCODE'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('you', 'O'),\n",
       " ('can', 'O'),\n",
       " ('visit', 'O'),\n",
       " ('his', 'O'),\n",
       " ('personal', 'O'),\n",
       " ('blog', 'O'),\n",
       " ('at', 'O'),\n",
       " ('www.johnsmithblog.com', 'I-URL'),\n",
       " ('.', 'O'),\n",
       " ('Follow', 'O'),\n",
       " ('him', 'O'),\n",
       " ('on', 'O'),\n",
       " ('Twitter', 'O'),\n",
       " ('with', 'O'),\n",
       " ('the', 'O'),\n",
       " ('handle', 'O'),\n",
       " ('@johnsmith123', 'B-USERNAME'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('For', 'O'),\n",
       " ('any', 'O'),\n",
       " ('inquiries', 'O'),\n",
       " ('about', 'O'),\n",
       " ('the', 'O'),\n",
       " ('university', 'O'),\n",
       " (\"'s\", 'O'),\n",
       " ('programs', 'O'),\n",
       " (',', 'O'),\n",
       " ('you', 'O'),\n",
       " ('can', 'O'),\n",
       " ('contact', 'O'),\n",
       " ('the', 'O'),\n",
       " ('administration', 'O'),\n",
       " ('office', 'O'),\n",
       " ('at', 'O'),\n",
       " ('admin@xyzuniversity.edu', 'I-EMAIL'),\n",
       " ('or', 'O'),\n",
       " ('call', 'O'),\n",
       " ('+5551234567', 'I-PHONE_NUMBER'),\n",
       " ('.', 'O'),\n",
       " ('The', 'O'),\n",
       " ('office', 'O'),\n",
       " ('is', 'O'),\n",
       " ('located', 'O'),\n",
       " ('at', 'O'),\n",
       " ('789', 'B-STREETADDRESS'),\n",
       " ('University', 'I-STREETADDRESS'),\n",
       " ('Boulevard', 'I-STREETADDRESS'),\n",
       " ('.', 'O'),\n",
       " ('\\n\\n', 'O'),\n",
       " ('Visit', 'O'),\n",
       " ('our', 'O'),\n",
       " ('official', 'O'),\n",
       " ('website', 'O'),\n",
       " ('at', 'O'),\n",
       " ('www.xyzuniversity.edu', 'I-URL'),\n",
       " ('for', 'O'),\n",
       " ('more', 'O'),\n",
       " ('information', 'O'),\n",
       " ('on', 'O'),\n",
       " ('courses', 'O'),\n",
       " ('and', 'O'),\n",
       " ('admission', 'O'),\n",
       " ('procedures', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8fe5868f-8e40-4bde-9049-66de5a108a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_pos': 1, 'end_pos': 2, 'label_group': 'FIRSTNAME'},\n",
       " {'start_pos': 24, 'end_pos': 25, 'label_group': 'FIRSTNAME'},\n",
       " {'start_pos': 27, 'end_pos': 30, 'label_group': 'STREETADDRESS'},\n",
       " {'start_pos': 31, 'end_pos': 32, 'label_group': 'CITY'},\n",
       " {'start_pos': 37, 'end_pos': 38, 'label_group': 'ZIPCODE'},\n",
       " {'start_pos': 54, 'end_pos': 55, 'label_group': 'MIDDLENAME'},\n",
       " {'start_pos': 60, 'end_pos': 61, 'label_group': 'LASTNAME'},\n",
       " {'start_pos': 78, 'end_pos': 81, 'label_group': 'STREETADDRESS'},\n",
       " {'start_pos': 82, 'end_pos': 83, 'label_group': 'CITY'},\n",
       " {'start_pos': 88, 'end_pos': 89, 'label_group': 'ZIPCODE'},\n",
       " {'start_pos': 107, 'end_pos': 108, 'label_group': 'USERNAME'},\n",
       " {'start_pos': 136, 'end_pos': 139, 'label_group': 'STREETADDRESS'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6badc0-e40a-4807-b5c4-ce874be0aa70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39adb3db-6d65-4bae-8d24-9ca66409f0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"spans\" style=\"line-height: 2.5; direction: ltr\">Meet \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Jane\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        FIRSTNAME\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       "Doe , a brilliant student at XYZ University . She can be reached at jane.doe@email.com or through her phone number +1234567890 . \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Jane\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        FIRSTNAME\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       "resides at \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    123\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        STREETADDRESS\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       "\n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Main\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "</span>\n",
       "\n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Street\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "</span>\n",
       ", \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Cityville\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        CITY\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       ". Her student ID is \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    987654\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        ZIPCODE\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       "and her personal website is www.janedoe.com . Connect with her on social media using the username \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    @janedoe\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        MIDDLENAME\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       ". \n",
       "\n",
       " Meanwhile , John \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Smith\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        LASTNAME\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       ", another outstanding student , can be contacted at john.smith@email.com or at +9876543210 . John lives at \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    456\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        STREETADDRESS\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       "\n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Oak\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "</span>\n",
       "\n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Avenue\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "</span>\n",
       ", \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Townsville\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        CITY\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       ". His student ID is \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    123456\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        ZIPCODE\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       ", and you can visit his personal blog at www.johnsmithblog.com . Follow him on Twitter with the handle \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    @johnsmith123\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        USERNAME\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       ". \n",
       "\n",
       " For any inquiries about the university 's programs , you can contact the administration office at admin@xyzuniversity.edu or call +5551234567 . The office is located at \n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    789\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "    <span style=\"background: #ddd; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
       "        STREETADDRESS\n",
       "    </span>\n",
       "</span>\n",
       "\n",
       "\n",
       "</span>\n",
       "\n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    University\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "</span>\n",
       "\n",
       "<span style=\"font-weight: bold; display: inline-block; position: relative; height: 60px;\">\n",
       "    Boulevard\n",
       "    \n",
       "<span style=\"background: #ddd; top: 40px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
       "</span>\n",
       "\n",
       "    \n",
       "</span>\n",
       ". \n",
       "\n",
       " Visit our official website at www.xyzuniversity.edu for more information on courses and admission procedures . </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_v, pred_v = zip(*word_labels)\n",
    "\n",
    "visualize_span(text, token_v, pred_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a9dfe07c-45c7-4d18-90c9-dab416470530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ba388de-1530-4653-8100-dd2bf2353549",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1010] Unable to set entity information for token 0 which is included in more than one span in entities, blocked, missing or outside.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, start, end \u001b[38;5;129;01min\u001b[39;00m actual_entities:\n\u001b[0;32m     26\u001b[0m     ent \u001b[38;5;241m=\u001b[39m Span(doc, start, end, label\u001b[38;5;241m=\u001b[39mlabel)\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ments\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(doc\u001b[38;5;241m.\u001b[39ments) \u001b[38;5;241m+\u001b[39m [ent]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Visualize using displacy\u001b[39;00m\n\u001b[0;32m     30\u001b[0m displacy\u001b[38;5;241m.\u001b[39mrender(doc, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m'\u001b[39m, page\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\spacy\\tokens\\doc.pyx:795\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\spacy\\tokens\\doc.pyx:832\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E1010] Unable to set entity information for token 0 which is included in more than one span in entities, blocked, missing or outside."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc, Span\n",
    "from spacy import displacy\n",
    "\n",
    "# Sample data\n",
    "full_string = \"Apple is headquartered in Cupertino, California.\"\n",
    "tokens = ['Apple', 'is', 'headquartered', 'in', 'Cupertino', ',', 'California', '.']\n",
    "predicted_labels = ['ORG', 'O', 'O', 'O', 'LOC', 'O', 'LOC', 'O']\n",
    "actual_labels = ['ORG', 'O', 'O', 'O', 'LOC', 'O', 'LOC', 'O']\n",
    "\n",
    "# Load a spaCy model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a spaCy Doc object\n",
    "doc = Doc(nlp.vocab, words=tokens)\n",
    "\n",
    "# Predicted entities\n",
    "predicted_entities = [(predicted_labels[i], i, i+1) for i in range(len(tokens)) if predicted_labels[i] != 'O']\n",
    "for label, start, end in predicted_entities:\n",
    "    ent = Span(doc, start, end, label=label)\n",
    "    doc.ents = list(doc.ents) + [ent]\n",
    "\n",
    "# Actual entities\n",
    "actual_entities = [(actual_labels[i], i, i+1) for i in range(len(tokens)) if actual_labels[i] != 'O']\n",
    "for label, start, end in actual_entities:\n",
    "    ent = Span(doc, start, end, label=label)\n",
    "    doc.ents = list(doc.ents) + [ent]\n",
    "\n",
    "# Visualize using displacy\n",
    "displacy.render(doc, style='ent', page=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e137c730-01cd-48c9-b084-f24f8031fdc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'ents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Visualize using displacy\u001b[39;00m\n\u001b[0;32m     19\u001b[0m doc \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m: words, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ments\u001b[39m\u001b[38;5;124m'\u001b[39m: ents, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m---> 20\u001b[0m \u001b[43mdisplacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\spacy\\displacy\\__init__.py:57\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(docs, style, page, minify, jupyter, options, manual)\u001b[0m\n\u001b[0;32m     55\u001b[0m renderer_func, converter \u001b[38;5;241m=\u001b[39m factories[style]\n\u001b[0;32m     56\u001b[0m renderer \u001b[38;5;241m=\u001b[39m renderer_func(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m---> 57\u001b[0m parsed \u001b[38;5;241m=\u001b[39m [converter(doc, options) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manual \u001b[38;5;28;01melse\u001b[39;00m docs  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manual:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\spacy\\displacy\\__init__.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     55\u001b[0m renderer_func, converter \u001b[38;5;241m=\u001b[39m factories[style]\n\u001b[0;32m     56\u001b[0m renderer \u001b[38;5;241m=\u001b[39m renderer_func(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m---> 57\u001b[0m parsed \u001b[38;5;241m=\u001b[39m [\u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manual \u001b[38;5;28;01melse\u001b[39;00m docs  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manual:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\spacy\\displacy\\__init__.py:210\u001b[0m, in \u001b[0;36mparse_ents\u001b[1;34m(doc, options)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate named entities in [{start: i, end: i, label: 'label'}] format.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03mdoc (Doc): Document to parse.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03moptions (Dict[str, Any]): NER-specific visualisation options.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03mRETURNS (dict): Generated entities keyed by text (original text) and ents.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m kb_url_template \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkb_url_template\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    202\u001b[0m ents \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    203\u001b[0m     {\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m: ent\u001b[38;5;241m.\u001b[39mstart_char,\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m: ent\u001b[38;5;241m.\u001b[39mend_char,\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: ent\u001b[38;5;241m.\u001b[39mlabel_,\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkb_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: ent\u001b[38;5;241m.\u001b[39mkb_id_ \u001b[38;5;28;01mif\u001b[39;00m ent\u001b[38;5;241m.\u001b[39mkb_id_ \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkb_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: kb_url_template\u001b[38;5;241m.\u001b[39mformat(ent\u001b[38;5;241m.\u001b[39mkb_id_) \u001b[38;5;28;01mif\u001b[39;00m kb_url_template \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    209\u001b[0m     }\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ments\u001b[49m\n\u001b[0;32m    211\u001b[0m ]\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ents:\n\u001b[0;32m    213\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(Warnings\u001b[38;5;241m.\u001b[39mW006)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'ents'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Sample data\n",
    "full_string = \"Apple is headquartered in Cupertino, California.\"\n",
    "tokens = ['Apple', 'is', 'headquartered', 'in', 'Cupertino', ',', 'California', '.']\n",
    "labels = ['ORG', 'O', 'O', 'O', 'LOC', 'O', 'LOC', 'O']\n",
    "\n",
    "# Combine tokens and labels into spaCy format\n",
    "entities = [{'start': 0, 'end': 5, 'label': 'ORG'}, {'start': 24, 'end': 34, 'label': 'LOC'}]\n",
    "\n",
    "# Convert tokens to a list of dictionaries\n",
    "words = [{'text': token, 'tag': ''} for token in tokens]\n",
    "\n",
    "# Create a list of tuples (text, label) for named entities\n",
    "ents = [(full_string[entity['start']:entity['end']], entity['label']) for entity in entities]\n",
    "\n",
    "# Visualize using displacy\n",
    "doc = {'words': words, 'ents': ents, 'title': None}\n",
    "displacy.render(doc, style='ent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b67de-e58e-4f89-be4c-bc539b86e172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f66af3-eee6-472d-9a3f-73a159b88479",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54d394c9-b1cf-41de-a3f4-42f7aed75694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original String: Your original sentence here.\n",
      "Reconstructed String: your original sentence here\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Replace 'bert-base-uncased' with the name of the model you are using\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Original string\n",
    "original_string = \"Your original sentence here.\"\n",
    "\n",
    "# Tokenize the original string\n",
    "tokens = tokenizer(original_string, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass to get predictions (you can replace this with your actual use case)\n",
    "# outputs = model(**tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**tokens).logits\n",
    "    \n",
    "predicted_token_class_ids = logits.argmax(-1)\n",
    "\n",
    "# Assuming you have word_ids, replace this with your actual word_ids\n",
    "word_ids = tokens.word_ids()\n",
    "\n",
    "# [0, 0, 1, 1, 1, 2, 2, 3, 4, 4, 5]\n",
    "tokens.word_ids()\n",
    "\n",
    "# Get the original words using word_ids\n",
    "original_words = [tokenizer.convert_ids_to_tokens(tokens['input_ids'][0][i].item()) for i in word_ids if i is not None]\n",
    "\n",
    "special_token_ids = tokenizer.convert_tokens_to_ids(tokenizer.special_tokens_map.values())\n",
    "filtered_words = [word for word in original_words if tokenizer.convert_tokens_to_ids([word])[0] not in special_token_ids]\n",
    "\n",
    "# Reconstruct the original string\n",
    "reconstructed_string = tokenizer.convert_tokens_to_string(filtered_words)\n",
    "\n",
    "print(\"Original String:\", original_string)\n",
    "print(\"Reconstructed String:\", reconstructed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e18c2ba-a280-4aab-abb7-a5e7078511ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youroriginalsentencehere'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0081e40b-0306-4b48-b6ef-2a1ad33d9c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your', 'original', 'sentence', 'here']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a2842ba-8c6c-42a7-940a-abbd64e78665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 1, 2, 3, 4, None]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f14a7c97-6085-4870-9df1-1c06e950edfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, None]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e8b090f-0bd3-4ff7-a63f-d7400496d0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b5839cf-70de-42c3-a5b2-de0d50aede28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get the original words and predicted labels using valid_indices\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# original_words = [tokenizer.convert_ids_to_tokens(word_ids[i].item()) for i in valid_indices\u001b[39;00m\n\u001b[0;32m      6\u001b[0m original_words \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][i]\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m valid_indices]\n\u001b[1;32m----> 8\u001b[0m filtered_predicted_labels \u001b[38;5;241m=\u001b[39m [predicted_labels[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m valid_indices]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create a dictionary to map each word to its predicted label\u001b[39;00m\n\u001b[0;32m     11\u001b[0m word_label_mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(original_words, filtered_predicted_labels))\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get the original words and predicted labels using valid_indices\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# original_words = [tokenizer.convert_ids_to_tokens(word_ids[i].item()) for i in valid_indices\u001b[39;00m\n\u001b[0;32m      6\u001b[0m original_words \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][i]\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m valid_indices]\n\u001b[1;32m----> 8\u001b[0m filtered_predicted_labels \u001b[38;5;241m=\u001b[39m [\u001b[43mpredicted_labels\u001b[49m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m valid_indices]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create a dictionary to map each word to its predicted label\u001b[39;00m\n\u001b[0;32m     11\u001b[0m word_label_mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(original_words, filtered_predicted_labels))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter out special tokens and None values\n",
    "valid_indices = [i for i, word_id in enumerate(word_ids) if word_id is not None and word_id not in tokenizer.all_special_ids]\n",
    "\n",
    "# Get the original words and predicted labels using valid_indices\n",
    "# original_words = [tokenizer.convert_ids_to_tokens(word_ids[i].item()) for i in valid_indices\n",
    "original_words = [tokenizer.convert_ids_to_tokens(tokens['input_ids'][0][i].item()) for i in valid_indices]\n",
    "\n",
    "filtered_predicted_labels = [predicted_labels[i] for i in valid_indices]\n",
    "\n",
    "# Create a dictionary to map each word to its predicted label\n",
    "word_label_mapping = dict(zip(original_words, filtered_predicted_labels))\n",
    "\n",
    "# Reconstruct the original string without special tokens\n",
    "reconstructed_string = tokenizer.convert_tokens_to_string(original_words)\n",
    "\n",
    "# Align predicted labels with the reconstructed string\n",
    "aligned_labels = [word_label_mapping[word] for word in original_words]\n",
    "\n",
    "print(\"Original String:\", original_string)\n",
    "print(\"Reconstructed String:\", reconstructed_string)\n",
    "print(\"Aligned Labels:\", aligned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce43a1ad-47ce-4148-a231-c648f6718940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: John Smith works at OpenAI in San Francisco.\n",
      "Word Labels: [('John', 'LABEL_1'), ('Smith', 'LABEL_1'), ('works', 'LABEL_1'), ('at', 'LABEL_1'), ('OpenAI', 'LABEL_1'), ('in', 'LABEL_1'), ('San', 'LABEL_1'), ('Francisco', 'LABEL_0'), ('.', 'LABEL_0')]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "import spacy\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer using Auto classes\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load spaCy model for tokenization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"John Smith works at OpenAI in San Francisco.\"\n",
    "\n",
    "# Step 1: Tokenize the text using spaCy for words\n",
    "words = [token.text for token in nlp(text)]\n",
    "\n",
    "# Step 2: Tokenize the text using the model's tokenizer and get word to subword mapping\n",
    "inputs = tokenizer(text, return_tensors='pt', return_offsets_mapping=False)\n",
    "word_ids = inputs.word_ids()\n",
    "\n",
    "# Step 3: Run inference\n",
    "outputs = model(**inputs).logits\n",
    "\n",
    "# Step 4: Create a list of which tokens or subwords correspond to a word using the word_ids variable\n",
    "word_subword_mapping = {}\n",
    "for i, word_id in enumerate(word_ids):\n",
    "    if word_id is not None:\n",
    "        if word_id not in word_subword_mapping:\n",
    "            word_subword_mapping[word_id] = []\n",
    "        word_subword_mapping[word_id].append(i)\n",
    "\n",
    "# Instantiate predictions variable\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "\n",
    "# Step 5: Iterate through pairs of words and subwords to count the majority label\n",
    "word_labels = []\n",
    "for word_id, subword_indices in word_subword_mapping.items():\n",
    "    subword_labels = predictions[0, subword_indices]\n",
    "    majority_label = torch.mode(subword_labels).values.item()\n",
    "    word_labels.append((words[word_id], model.config.id2label[majority_label]))\n",
    "\n",
    "# Display results\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Word Labels:\", word_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "295fdb4f-e96d-4d02-9f08-b5e71a5dae9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c83339e-babd-4f41-8253-6ffea161f8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (475915208.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    if token is not None and token\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted labels from the output of the model\n",
    "predicted_labels = torch.argmax(outputs.logits, dim=2).squeeze().tolist()\n",
    "\n",
    "# Filter out special tokens (those with token type ID = 0)\n",
    "special_token_ids = tokenizer.convert_tokens_to_ids(tokenizer.special_tokens_map.values())\n",
    "filtered_word_ids = [word_id for word_id in word_ids if word_id not in special_token_ids]\n",
    "\n",
    "# Get the original words using filtered_word_ids\n",
    "original_words = [tokenizer.convert_ids_to_tokens(word_id.item()) for word_id in filtered_word_ids]\n",
    "\n",
    "def filter_post(token):\n",
    "    if token is not None and token\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Filter predicted labels to maintain alignment\n",
    "filtered_predicted_labels = [predicted_label for predicted_label, word_id in zip(predicted_labels, word_ids) if word_id not in special_token_ids]\n",
    "\n",
    "# Create a dictionary to map each word to its predicted label\n",
    "word_label_mapping = dict(zip(original_words, filtered_predicted_labels))\n",
    "\n",
    "# Reconstruct the original string without special tokens\n",
    "reconstructed_string = tokenizer.convert_tokens_to_string(original_words)\n",
    "\n",
    "# Align predicted labels with the reconstructed string\n",
    "aligned_labels = [word_label_mapping[word] for word in original_words]\n",
    "\n",
    "print(\"Original String:\", original_string)\n",
    "print(\"Reconstructed String:\", reconstructed_string)\n",
    "print(\"Aligned Labels:\", aligned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0267ce0-da29-4821-8185-0126edf5f178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'your', 'original', 'sentence', 'here', '.', '[SEP]']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e31fe05-4e98-4302-bef6-19141ec8e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**tokens).logits\n",
    "    \n",
    "predicted_labels = logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5cf36a10-25fe-4d42-90c7-1ec7d10acf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_class_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1464370b-9499-422e-a2e4-30413b0fec72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs.logits, dim=2).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1c10b-55e7-47d5-9d3f-4ddd765dc80e",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4acad6ff-26be-4b1f-967f-ff1514868005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_tokens_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0468c26-2a91-4600-9e5e-d4cce62fc3c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '▁Design',\n",
       " '▁Thinking',\n",
       " '▁for',\n",
       " '▁innovation',\n",
       " '▁reflex',\n",
       " 'ion',\n",
       " '-',\n",
       " 'Av',\n",
       " 'ril',\n",
       " '▁2021',\n",
       " '-',\n",
       " 'N',\n",
       " 'atha',\n",
       " 'lie',\n",
       " '▁S',\n",
       " 'ylla',\n",
       " '▁Challenge',\n",
       " '▁&',\n",
       " '▁selection',\n",
       " '▁The',\n",
       " '▁tool',\n",
       " '▁I',\n",
       " '▁use',\n",
       " '▁to',\n",
       " '▁help',\n",
       " '▁all',\n",
       " '▁stakeholders',\n",
       " '▁finding',\n",
       " '▁their',\n",
       " '▁way',\n",
       " '▁through',\n",
       " '▁the',\n",
       " '▁complexity',\n",
       " '▁of',\n",
       " '▁a',\n",
       " '▁project',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '.',\n",
       " '▁What',\n",
       " '▁exactly',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '?',\n",
       " '▁According',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁definition',\n",
       " '▁of',\n",
       " '▁Buz',\n",
       " 'an',\n",
       " '▁T',\n",
       " '.',\n",
       " '▁and',\n",
       " '▁Buz',\n",
       " 'an',\n",
       " '▁B',\n",
       " '.',\n",
       " '▁(',\n",
       " '1999',\n",
       " ',',\n",
       " '▁Des',\n",
       " 's',\n",
       " 'ine',\n",
       " '-',\n",
       " 'moi',\n",
       " '▁l',\n",
       " \"'\",\n",
       " 'intelligence',\n",
       " '.',\n",
       " '▁Paris',\n",
       " ':',\n",
       " '▁Les',\n",
       " '▁É',\n",
       " 'dition',\n",
       " 's',\n",
       " '▁d',\n",
       " \"'\",\n",
       " 'Organ',\n",
       " 'isation',\n",
       " '.',\n",
       " ')',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁(',\n",
       " 'or',\n",
       " '▁heuristic',\n",
       " '▁diagram',\n",
       " ')',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁graphic',\n",
       " '▁representation',\n",
       " '▁technique',\n",
       " '▁that',\n",
       " '▁follows',\n",
       " '▁the',\n",
       " '▁natural',\n",
       " '▁functioning',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁and',\n",
       " '▁allows',\n",
       " '▁the',\n",
       " '▁brain',\n",
       " \"'\",\n",
       " 's',\n",
       " '▁potential',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁released',\n",
       " '.',\n",
       " '▁Cf',\n",
       " '▁Annex',\n",
       " '1',\n",
       " '▁This',\n",
       " '▁tool',\n",
       " '▁has',\n",
       " '▁many',\n",
       " '▁advantages',\n",
       " ':',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁accessible',\n",
       " '▁to',\n",
       " '▁all',\n",
       " '▁and',\n",
       " '▁does',\n",
       " '▁not',\n",
       " '▁require',\n",
       " '▁significant',\n",
       " '▁material',\n",
       " '▁investment',\n",
       " '▁and',\n",
       " '▁can',\n",
       " '▁be',\n",
       " '▁done',\n",
       " '▁quickly',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁scalable',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁allows',\n",
       " '▁categorization',\n",
       " '▁and',\n",
       " '▁linking',\n",
       " '▁of',\n",
       " '▁information',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁can',\n",
       " '▁be',\n",
       " '▁applied',\n",
       " '▁to',\n",
       " '▁any',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁situation',\n",
       " ':',\n",
       " '▁note',\n",
       " 'taking',\n",
       " ',',\n",
       " '▁problem',\n",
       " '▁solving',\n",
       " ',',\n",
       " '▁analysis',\n",
       " ',',\n",
       " '▁creation',\n",
       " '▁of',\n",
       " '▁new',\n",
       " '▁ideas',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁suitable',\n",
       " '▁for',\n",
       " '▁all',\n",
       " '▁people',\n",
       " '▁and',\n",
       " '▁is',\n",
       " '▁easy',\n",
       " '▁to',\n",
       " '▁learn',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁is',\n",
       " '▁fun',\n",
       " '▁and',\n",
       " '▁encourages',\n",
       " '▁exchanges',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁makes',\n",
       " '▁visible',\n",
       " '▁the',\n",
       " '▁dimension',\n",
       " '▁of',\n",
       " '▁projects',\n",
       " ',',\n",
       " '▁opportunities',\n",
       " ',',\n",
       " '▁interconnections',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁synthesize',\n",
       " 's',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁makes',\n",
       " '▁the',\n",
       " '▁project',\n",
       " '▁understandable',\n",
       " '▁•',\n",
       " '▁It',\n",
       " '▁allows',\n",
       " '▁you',\n",
       " '▁to',\n",
       " '▁explore',\n",
       " '▁ideas',\n",
       " '▁The',\n",
       " '▁creation',\n",
       " '▁of',\n",
       " '▁a',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁starts',\n",
       " '▁with',\n",
       " '▁an',\n",
       " '▁idea',\n",
       " '/',\n",
       " 'problem',\n",
       " '▁located',\n",
       " '▁at',\n",
       " '▁its',\n",
       " '▁center',\n",
       " '.',\n",
       " '▁This',\n",
       " '▁starting',\n",
       " '▁point',\n",
       " '▁generates',\n",
       " '▁ideas',\n",
       " '/',\n",
       " 'work',\n",
       " '▁areas',\n",
       " ',',\n",
       " '▁incremented',\n",
       " '▁around',\n",
       " '▁this',\n",
       " '▁center',\n",
       " '▁in',\n",
       " '▁a',\n",
       " '▁radial',\n",
       " '▁structure',\n",
       " ',',\n",
       " '▁which',\n",
       " '▁in',\n",
       " '▁turn',\n",
       " '▁is',\n",
       " '▁completed',\n",
       " '▁with',\n",
       " '▁as',\n",
       " '▁many',\n",
       " '▁branches',\n",
       " '▁as',\n",
       " '▁new',\n",
       " '▁ideas',\n",
       " '.',\n",
       " '▁This',\n",
       " '▁tool',\n",
       " '▁enables',\n",
       " '▁creativity',\n",
       " '▁and',\n",
       " '▁logic',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁mobilized',\n",
       " ',',\n",
       " '▁it',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁map',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁thoughts',\n",
       " '.',\n",
       " '▁Creativity',\n",
       " '▁is',\n",
       " '▁enhanced',\n",
       " '▁because',\n",
       " '▁participants',\n",
       " '▁feel',\n",
       " '▁comfortable',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁method',\n",
       " '.',\n",
       " '▁Application',\n",
       " '▁&',\n",
       " '▁Insight',\n",
       " '▁I',\n",
       " '▁start',\n",
       " '▁the',\n",
       " '▁process',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁creation',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '▁standing',\n",
       " '▁around',\n",
       " '▁a',\n",
       " '▁large',\n",
       " '▁board',\n",
       " '▁(',\n",
       " 'white',\n",
       " '▁or',\n",
       " '▁paper',\n",
       " '▁board',\n",
       " ')',\n",
       " '.',\n",
       " '▁In',\n",
       " '▁the',\n",
       " '▁center',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁board',\n",
       " ',',\n",
       " '▁I',\n",
       " '▁write',\n",
       " '▁and',\n",
       " '▁highlight',\n",
       " '▁the',\n",
       " '▁topic',\n",
       " '▁to',\n",
       " '▁design',\n",
       " '.',\n",
       " '▁Through',\n",
       " '▁a',\n",
       " '▁series',\n",
       " '▁of',\n",
       " '▁questions',\n",
       " ',',\n",
       " '▁I',\n",
       " '▁guide',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '▁in',\n",
       " '▁modelling',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '.',\n",
       " '▁I',\n",
       " '▁adapt',\n",
       " '▁the',\n",
       " '▁series',\n",
       " '▁of',\n",
       " '▁questions',\n",
       " '▁according',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁topic',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁addressed',\n",
       " '.',\n",
       " '▁In',\n",
       " '▁the',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁questions',\n",
       " ',',\n",
       " '▁we',\n",
       " '▁can',\n",
       " '▁use',\n",
       " ':',\n",
       " '▁who',\n",
       " ',',\n",
       " '▁what',\n",
       " ',',\n",
       " '▁when',\n",
       " ',',\n",
       " '▁where',\n",
       " ',',\n",
       " '▁why',\n",
       " ',',\n",
       " '▁how',\n",
       " ',',\n",
       " '▁how',\n",
       " '▁much',\n",
       " '.',\n",
       " '▁The',\n",
       " '▁use',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁“',\n",
       " 'why',\n",
       " '”',\n",
       " '▁is',\n",
       " '▁very',\n",
       " '▁interesting',\n",
       " '▁to',\n",
       " '▁understand',\n",
       " '▁the',\n",
       " '▁origin',\n",
       " '.',\n",
       " '▁By',\n",
       " '▁this',\n",
       " '▁way',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁interviewed',\n",
       " '▁person',\n",
       " '▁free',\n",
       " 's',\n",
       " '▁itself',\n",
       " '▁from',\n",
       " '▁paradigms',\n",
       " '▁and',\n",
       " '▁thus',\n",
       " '▁dares',\n",
       " '▁to',\n",
       " '▁propose',\n",
       " '▁new',\n",
       " '▁ideas',\n",
       " '▁/',\n",
       " '▁ways',\n",
       " '▁of',\n",
       " '▁functioning',\n",
       " '.',\n",
       " '▁I',\n",
       " '▁plan',\n",
       " '▁two',\n",
       " '▁hours',\n",
       " '▁for',\n",
       " '▁a',\n",
       " '▁workshop',\n",
       " '.',\n",
       " '▁Design',\n",
       " '▁Thinking',\n",
       " '▁for',\n",
       " '▁innovation',\n",
       " '▁reflex',\n",
       " 'ion',\n",
       " '-',\n",
       " 'Av',\n",
       " 'ril',\n",
       " '▁2021',\n",
       " '-',\n",
       " 'N',\n",
       " 'atha',\n",
       " 'lie',\n",
       " '▁S',\n",
       " 'ylla',\n",
       " '▁After',\n",
       " '▁modelling',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁on',\n",
       " '▁paper',\n",
       " ',',\n",
       " '▁I',\n",
       " '▁propose',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁participants',\n",
       " '▁a',\n",
       " '▁digital',\n",
       " '▁visualization',\n",
       " '▁of',\n",
       " '▁their',\n",
       " '▁work',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁addition',\n",
       " '▁of',\n",
       " '▁color',\n",
       " '▁codes',\n",
       " ',',\n",
       " '▁images',\n",
       " '▁and',\n",
       " '▁interconnections',\n",
       " '.',\n",
       " '▁This',\n",
       " '▁second',\n",
       " '▁workshop',\n",
       " '▁also',\n",
       " '▁last',\n",
       " 's',\n",
       " '▁two',\n",
       " '▁hours',\n",
       " '▁and',\n",
       " '▁allows',\n",
       " '▁the',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " '▁to',\n",
       " '▁evolve',\n",
       " '.',\n",
       " '▁Once',\n",
       " '▁familiarized',\n",
       " '▁with',\n",
       " '▁it',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '▁discover',\n",
       " '▁the',\n",
       " '▁power',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁tool',\n",
       " '.',\n",
       " '▁Then',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁second',\n",
       " '▁workshop',\n",
       " '▁brings',\n",
       " '▁out',\n",
       " '▁even',\n",
       " '▁more',\n",
       " '▁ideas',\n",
       " '▁and',\n",
       " '▁constructive',\n",
       " '▁exchanges',\n",
       " '▁between',\n",
       " '▁the',\n",
       " '▁stakeholders',\n",
       " '.',\n",
       " '▁Around',\n",
       " '▁this',\n",
       " '▁new',\n",
       " '▁mind',\n",
       " '▁map',\n",
       " ',',\n",
       " '▁they',\n",
       " '▁have',\n",
       " '▁learned',\n",
       " '▁to',\n",
       " '▁work',\n",
       " '▁together',\n",
       " '▁and',\n",
       " '▁want',\n",
       " '▁to',\n",
       " '▁make',\n",
       " '▁visible',\n",
       " '▁the',\n",
       " '▁untold',\n",
       " '▁ideas',\n",
       " '.',\n",
       " '▁I',\n",
       " '▁now',\n",
       " '▁present',\n",
       " '▁all',\n",
       " '▁the',\n",
       " '▁projects',\n",
       " '▁I',\n",
       " '▁manage',\n",
       " '▁in',\n",
       " '▁this',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁format',\n",
       " '▁in',\n",
       " '▁order',\n",
       " '▁to',\n",
       " '▁ease',\n",
       " '▁rapid',\n",
       " '▁understanding',\n",
       " '▁for',\n",
       " '▁decision',\n",
       " '-',\n",
       " 'makers',\n",
       " '.',\n",
       " '▁These',\n",
       " '▁presentations',\n",
       " '▁are',\n",
       " '▁the',\n",
       " '▁core',\n",
       " '▁of',\n",
       " '▁my',\n",
       " '▁business',\n",
       " '▁models',\n",
       " '.',\n",
       " '▁The',\n",
       " '▁decision',\n",
       " '-',\n",
       " 'makers',\n",
       " '▁are',\n",
       " '▁thus',\n",
       " '▁able',\n",
       " '▁to',\n",
       " '▁identify',\n",
       " '▁the',\n",
       " '▁opportunities',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁projects',\n",
       " '▁and',\n",
       " '▁can',\n",
       " '▁take',\n",
       " '▁quick',\n",
       " '▁decisions',\n",
       " '▁to',\n",
       " '▁validate',\n",
       " '▁them',\n",
       " '.',\n",
       " '▁They',\n",
       " '▁find',\n",
       " '▁answers',\n",
       " '▁to',\n",
       " '▁their',\n",
       " '▁questions',\n",
       " '▁thank',\n",
       " '▁to',\n",
       " '▁a',\n",
       " '▁schematic',\n",
       " '▁representation',\n",
       " '.',\n",
       " '▁Approach',\n",
       " '▁What',\n",
       " '▁I',\n",
       " '▁find',\n",
       " '▁amazing',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁facilitation',\n",
       " '▁of',\n",
       " '▁this',\n",
       " '▁type',\n",
       " '▁of',\n",
       " '▁workshop',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁participants',\n",
       " '▁commitment',\n",
       " '▁for',\n",
       " '▁the',\n",
       " '▁project',\n",
       " '.',\n",
       " '▁This',\n",
       " '▁tool',\n",
       " '▁helps',\n",
       " '▁to',\n",
       " '▁give',\n",
       " '▁meaning',\n",
       " '.',\n",
       " '▁The',\n",
       " '▁participants',\n",
       " '▁appropriate',\n",
       " '▁the',\n",
       " '▁story',\n",
       " '▁and',\n",
       " '▁want',\n",
       " '▁to',\n",
       " '▁keep',\n",
       " '▁writing',\n",
       " '▁it',\n",
       " '.',\n",
       " '▁Then',\n",
       " ',',\n",
       " '▁they',\n",
       " '▁easily',\n",
       " '▁become',\n",
       " '▁actors',\n",
       " '▁or',\n",
       " '▁sponsors',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁project',\n",
       " '.',\n",
       " '▁A',\n",
       " '▁trust',\n",
       " '▁relationship',\n",
       " '▁is',\n",
       " '▁built',\n",
       " ',',\n",
       " '▁thus',\n",
       " '▁facilitating',\n",
       " '▁the',\n",
       " '▁implementation',\n",
       " '▁of',\n",
       " '▁related',\n",
       " '▁actions',\n",
       " '.',\n",
       " '▁Design',\n",
       " '▁Thinking',\n",
       " '▁for',\n",
       " '▁innovation',\n",
       " '▁reflex',\n",
       " 'ion',\n",
       " '-',\n",
       " 'Av',\n",
       " 'ril',\n",
       " '▁2021',\n",
       " '-',\n",
       " 'N',\n",
       " 'atha',\n",
       " 'lie',\n",
       " '▁S',\n",
       " 'ylla',\n",
       " '▁Annex',\n",
       " '▁1',\n",
       " ':',\n",
       " '▁Mind',\n",
       " '▁Map',\n",
       " '▁Shared',\n",
       " '▁facilities',\n",
       " '▁project',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b93fc7f0-2d89-4b2a-8248-d4dd90560823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'your': tensor([0, 1, 1, 1, 0, 0, 1])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50bcdafe-3347-4991-a35a-208da1191f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your', 'original', 'sentence', 'here']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35e892ed-d5e7-4f9a-9d68-e1a52192c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_label_mapping = dict(zip(filtered_words, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc277a27-1195-4535-806a-cd5913c7a364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'your': tensor([0, 1, 1, 1, 0, 0, 1])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53896c3f-6a74-4e6b-81c5-2f8e9b72c1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your', 'original', 'sentence', 'here']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f2d6a-0d61-4082-b524-3b1609795cdc",
   "metadata": {},
   "source": [
    "# Latest Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97d7ab82-91dc-4418-adf8-c07d31687536",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'original'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m reconstructed_string \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_string(filtered_words)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Align predicted labels with the reconstructed string\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m aligned_labels \u001b[38;5;241m=\u001b[39m [word_label_mapping[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m filtered_words]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal String:\u001b[39m\u001b[38;5;124m\"\u001b[39m, original_string)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReconstructed String:\u001b[39m\u001b[38;5;124m\"\u001b[39m, reconstructed_string)\n",
      "Cell \u001b[1;32mIn[48], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m reconstructed_string \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_string(filtered_words)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Align predicted labels with the reconstructed string\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m aligned_labels \u001b[38;5;241m=\u001b[39m [\u001b[43mword_label_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m filtered_words]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal String:\u001b[39m\u001b[38;5;124m\"\u001b[39m, original_string)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReconstructed String:\u001b[39m\u001b[38;5;124m\"\u001b[39m, reconstructed_string)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'original'"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map each word to its predicted label\n",
    "word_label_mapping = dict(zip(filtered_words, predicted_labels))\n",
    "\n",
    "# Reconstruct the original string without special tokens\n",
    "reconstructed_string = tokenizer.convert_tokens_to_string(filtered_words)\n",
    "\n",
    "# Align predicted labels with the reconstructed string\n",
    "aligned_labels = [word_label_mapping[word] for word in filtered_words]\n",
    "\n",
    "print(\"Original String:\", original_string)\n",
    "print(\"Reconstructed String:\", reconstructed_string)\n",
    "print(\"Aligned Labels:\", aligned_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
